{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 11/11 [00:00<00:00, 2485.71it/s]\n",
      "Summarizing documents:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 161fa426-161a-4993-bb37-e731fb9833d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:   9%|▉         | 1/11 [00:01<00:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 0f07aa9d-ca5d-4f25-828c-5c56e80e0c5c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  18%|█▊        | 2/11 [00:02<00:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 3a7700da-fbc5-47ff-8514-877af7c98f18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 19c051a6-76ff-4433-9fcf-b54f5a924ca1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  36%|███▋      | 4/11 [00:06<00:10,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: a22bdf00-8cbd-46a6-bd5b-d2ae5c05c9ee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  45%|████▌     | 5/11 [00:07<00:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 223fc3bf-4335-4df9-ad1a-19e9c5372421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  55%|█████▍    | 6/11 [00:09<00:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: a527be08-dc3e-4f85-8ac0-1caeea198fdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: b6b17861-1ad8-4bae-98a6-35edbb5578ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  73%|███████▎  | 8/11 [00:12<00:04,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: c105ace6-ac22-49bf-b2a8-c5b0d617a4dd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  82%|████████▏ | 9/11 [00:15<00:03,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 2ffead00-851a-4eb8-845b-29c307547668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:  91%|█████████ | 10/11 [00:17<00:01,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 40e7186c-ea33-49a6-8941-3b0ac3d4b6b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents: 100%|██████████| 11/11 [00:18<00:00,  1.64s/it]\n",
      "Generating embeddings: 100%|██████████| 11/11 [00:00<00:00, 31.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer, DocumentSummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.indices.document_summary import DocumentSummaryIndexEmbeddingRetriever\n",
    "import nest_asyncio\n",
    "import os\n",
    "import openai\n",
    "import logging\n",
    "import sys\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def get_pdf_urls(base_path):\n",
    "    all_files = []  # List to store all relevant files\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        # Filter and add files to the list, excluding system and temporary files\n",
    "        files = [file for file in files if not file.startswith('.') and not file.startswith('~$')]\n",
    "        full_paths = [os.path.join(root, file) for file in files]\n",
    "        all_files.extend(full_paths)\n",
    "    return all_files\n",
    "\n",
    "def pdf_reader(base_path):\n",
    "    llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "    pdfs = get_pdf_urls(base_path)\n",
    "    pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "    for pdf in pdfs:\n",
    "        documents = pdf_loader.load_data(pdf)\n",
    "    return documents\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def initialize_document_summary_index(documents):\n",
    "    \"\"\"Initializes and returns a DocumentSummaryIndex from a list of documents.\"\"\"\n",
    "    # Initialize OpenAI model and splitter\n",
    "    chatgpt = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    \n",
    "    # Get the response synthesizer set for summarizing documents\n",
    "    response_synthesizer = get_response_synthesizer(\n",
    "        response_mode=\"tree_summarize\", use_async=True\n",
    "    )\n",
    "    \n",
    "    # Build and return the document summary index\n",
    "    doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "        documents,\n",
    "        llm=chatgpt,\n",
    "        transformations=[splitter],\n",
    "        response_synthesizer=response_synthesizer,\n",
    "        show_progress=True\n",
    "    )\n",
    "    return doc_summary_index\n",
    "\n",
    "def create_retriever(doc_summary_index):\n",
    "    retriever = DocumentSummaryIndexEmbeddingRetriever(doc_summary_index, similarity_top_k=1)\n",
    "    return retriever\n",
    "\n",
    "def setup_query_engine():\n",
    "    base_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/knowledge_database\"\n",
    "    documents = pdf_reader(base_path)\n",
    "    doc_summary_index = initialize_document_summary_index(documents)\n",
    "    retriever = create_retriever(doc_summary_index)\n",
    "\n",
    "    response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "    query_engine = RetrieverQueryEngine(\n",
    "        retriever=retriever,\n",
    "        response_synthesizer=response_synthesizer,\n",
    "    )\n",
    "    return query_engine\n",
    "\n",
    "\n",
    "query_engine = setup_query_engine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can improve the turnover of your parts department by establishing a culture of continuous improvement within your dealership's inventory management processes. Encourage feedback from staff members involved in inventory handling, regularly review and refine inventory management procedures based on performance metrics and feedback. By continuously seeking ways to enhance efficiency and adapt to evolving market dynamics, you can reduce the risk of surplus auto parts inventory and improve overall operational effectiveness.\n"
     ]
    }
   ],
   "source": [
    "# Now, use query_engine to perform queries\n",
    "response = query_engine.query(\"How can i impreve the turnover of my parts department?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "partsmatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
