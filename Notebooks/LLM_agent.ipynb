{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 540, 'bearing ntn 6203llu/2a 40x17x12', -100.0, 0.0, 0, 'motovan', 0.0, 0, 0.0, 0, 0.0, 0.0, 1, 'obsolete', 0.0, 9.99, 1.0, 0, 6, '004-153', 0.0, 0, 0.0, 18)\n",
      "(0.0, 365, 'hi-flo o-filt hon 15412-hm5-a1', -45.99, 0.0, 0, 'thibault canada', 1.0, 0, 0.0, 0, 0.0, 365.0, 1, 'nearing_obsolete', 0.0, 4.99, 0.7905064658, 0, 3, '004hf113', 100.0, 0, 0.3671742809, 8)\n",
      "(0.0, 365, 'new style universal cruise ctr', 0.11, 0.0, 0, 'thibault canada', 1.0, 0, 0.0, 0, 0.0, 365.0, 1, 'nearing_obsolete', 0.0, 18.99, 0.7555531794, 0, 9, '0069922bc', 100.0, 0, 0.4406091371, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['parts', 'sales']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text, inspect\n",
    "from llama_index.core import SQLDatabase\n",
    "# Path to your database file\n",
    "db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "# \"r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\"\n",
    "\n",
    "# Create an engine instance\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection using raw SQL\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM parts LIMIT 3\"))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "tables = ['sales', 'parts']\n",
    "# sql_database = SQLDatabase(engine, include_tables=tables,sample_rows_in_table_info=5)\n",
    "sql_database = SQLDatabase(engine, sample_rows_in_table_info=2)#by default3 (actually)\n",
    "list(sql_database._all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will likely need to break this up into 3 components:\n",
    "1. Targeted responses\n",
    "2. Tabular data\n",
    "3. Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from sqlalchemy import text\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "def generate_plotly_visual(df, chart_type, title, x_axis_label, y_axis_label, hover_labels):\n",
    "    # Filtering existing hover data columns\n",
    "    hover_data = [col for col in hover_labels if col in df.columns]\n",
    "\n",
    "    # Preparing customdata correctly, ensuring it matches the data length\n",
    "    custom_data_adjusted = df[hover_data].values if hover_data else None\n",
    "\n",
    "    # Building the hover template\n",
    "    hover_template = \"<br>\".join([f\"{col}: %{{customdata[{i}]}}\" for i, col in enumerate(hover_data)])\n",
    "\n",
    "    if chart_type == \"line\":\n",
    "        fig = px.line(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "        if custom_data_adjusted is not None:\n",
    "            fig.update_traces(customdata=custom_data_adjusted, hovertemplate=hover_template + \"<extra></extra>\")\n",
    "\n",
    "    elif chart_type == \"bar\":\n",
    "        fig = go.Figure()\n",
    "        for col in df.columns[1:]:\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=df[df.columns[0]], \n",
    "                y=df[col],\n",
    "                name=col,\n",
    "                customdata=custom_data_adjusted,\n",
    "                hovertemplate=hover_template + \"<extra></extra>\"\n",
    "            ))\n",
    "        fig.update_layout(title=title, xaxis_title=x_axis_label, yaxis_title=y_axis_label, barmode='group')\n",
    "\n",
    "    elif chart_type == \"scatter\":\n",
    "        fig = px.scatter(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "        if custom_data_adjusted is not None:\n",
    "            fig.update_traces(customdata=custom_data_adjusted, hovertemplate=hover_template + \"<extra></extra>\")\n",
    "\n",
    "    elif chart_type == \"pie\":\n",
    "        fig = px.pie(df, names=df.columns[0], values=df.columns[1], title=title)\n",
    "        if custom_data_adjusted is not None:\n",
    "            # Ensure each column of custom_data_adjusted matches the length of the main data\n",
    "            custom_data_adjusted = np.array([custom_data_adjusted[:, i] if i < custom_data_adjusted.shape[1] else ['N/A']*len(df) for i in range(len(hover_data))]).T\n",
    "            fig.update_traces(customdata=custom_data_adjusted, hovertemplate=hover_template + \"<extra></extra>\")\n",
    "\n",
    "    else:\n",
    "        fig = px.scatter(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "        if custom_data_adjusted is not None:\n",
    "            fig.update_traces(customdata=custom_data_adjusted, hovertemplate=hover_template + \"<extra></extra>\")\n",
    "\n",
    "    # Apply common layout updates\n",
    "    fig.update_layout(\n",
    "        title={'text': title, 'y':0.95, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
    "        xaxis_title=x_axis_label,\n",
    "        yaxis_title=y_axis_label,\n",
    "        hovermode=\"closest\",\n",
    "        plot_bgcolor='white',  \n",
    "        paper_bgcolor='white',  \n",
    "        font=dict(family=\"Arial, sans-serif\", size=12, color=\"Gray\"),\n",
    "        xaxis=dict(showline=True, linecolor='Gray', linewidth=1, tickformat=',', title_standoff=10, tickfont=dict(size=14), titlefont=dict(size=16)),\n",
    "        yaxis=dict(showline=True, linecolor='Gray', linewidth=1, tickformat=',', title_standoff=10, tickfont=dict(size=14), titlefont=dict(size=16)),\n",
    "        legend=dict(x=0.5, y=-0.175, xanchor='center', yanchor='top', orientation='h', bgcolor='rgba(255,255,255,0.8)', bordercolor='Gray', borderwidth=1, font=dict(size=16)),\n",
    "        margin=dict(l=50, r=50, t=50, b=0)\n",
    "    )\n",
    "\n",
    "    return fig.show()\n",
    "\n",
    "def extract_chart_details(query_engine, user_input):\n",
    "    text_qa_template_str = (\n",
    "        \"Given the query: '{query_str}', extract the following details, adding hover data to enhance the utility of the charts:\\n\"\n",
    "        \"1. Chart type (e.g., bar, line, pie, etc.)\\n\"\n",
    "        \"2. Title for the chart\\n\"\n",
    "        \"3. X-axis label\\n\"\n",
    "        \"4. Y-axis label\\n\"\n",
    "        \"5. Additional columns for hover data\\n\"\n",
    "        \"\\n\"\n",
    "        \"Provide the details in the following format:\\n\"\n",
    "        \"Chart type: <type>\\n\"\n",
    "        \"Title: <title>\\n\"\n",
    "        \"X-axis label: <label>\\n\"\n",
    "        \"Y-axis label: <label>\\n\"\n",
    "        \"Hover data: <column1>, <column2>, ...\\n\"\n",
    "    )\n",
    "    text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "    \n",
    "    prompt = text_qa_template.format(query_str=user_input)\n",
    "    response = query_engine.query(prompt)\n",
    "    logging.info(f\"LLM Response: {response.response.strip()}\")\n",
    "    response_text = response.response.strip()\n",
    "    lines = response_text.split('\\n')\n",
    "    \n",
    "    chart_type = \"bar\"  # Default value\n",
    "    title = \"Generated Chart\"\n",
    "    x_axis_label = \"X Axis\"\n",
    "    y_axis_label = \"Y Axis\"\n",
    "    hover_data = []\n",
    "\n",
    "    for line in lines:\n",
    "        if \"Chart type:\" in line:\n",
    "            chart_type = line.split(\":\", 1)[1].strip().lower()\n",
    "        elif \"Title:\" in line:\n",
    "            title = line.split(\":\", 1)[1].strip()\n",
    "        elif \"X-axis label:\" in line:\n",
    "            x_axis_label = line.split(\":\", 1)[1].strip()\n",
    "        elif \"Y-axis label:\" in line:\n",
    "            y_axis_label = line.split(\":\", 1)[1].strip()\n",
    "        elif \"Hover data:\" in line:\n",
    "            hover_data = [col.strip().lower().replace(' ', '_') for col in line.split(\":\", 1)[1].strip().split(',')]\n",
    "    return {\n",
    "        \"chart_type\": chart_type, \n",
    "        \"title\": title, \n",
    "        \"x_axis_label\": x_axis_label, \n",
    "        \"y_axis_label\": y_axis_label, \n",
    "        \"hover_labels\": hover_data\n",
    "    }\n",
    "\n",
    "\n",
    "def output_sql_query_to_graph(result_data, columns, chart_type, title, x_axis_label, y_axis_label, hover_labels):\n",
    "    result_df = pd.DataFrame(result_data, columns=columns)\n",
    "    hovertext = {col: True for col in hover_labels} if hover_labels else None\n",
    "    fig = generate_plotly_visual(result_df, chart_type, title, x_axis_label, y_axis_label, hovertext)\n",
    "    fig.show()\n",
    "\n",
    "def handle_visual_query(query_engine, user_input):\n",
    "    sql_query = query_engine.query(user_input, return_sql=True)\n",
    "    with query_engine.engine.connect() as connection:\n",
    "        result = connection.execute(text(sql_query))\n",
    "        result_data = result.fetchall()\n",
    "        columns = result.keys()\n",
    "    chart_type, title, x_axis_label, y_axis_label, hover_labels = extract_chart_details(query_engine, user_input)\n",
    "    return output_sql_query_to_graph(result_data, columns, chart_type, title, x_axis_label, y_axis_label, hover_labels)\n",
    "\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self):\n",
    "        self.sql_keywords = [\n",
    "            'SELECT', 'DROP', 'INSERT', 'DELETE', 'UPDATE', 'CREATE', \n",
    "            'ALTER', 'EXEC', 'UNION', 'DECLARE'\n",
    "        ]\n",
    "\n",
    "    def remove_sql_keywords(self, text):\n",
    "        pattern = r'\\b(' + '|'.join(self.sql_keywords) + r')\\b'\n",
    "        return re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    def normalize_whitespace_and_characters(self, text):\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s%]', '', text)\n",
    "        return text\n",
    "\n",
    "    def preprocess_query(self, user_input):\n",
    "        user_input = user_input.lower().strip()\n",
    "        user_input = re.sub(r'(\\d+)%', lambda match: str(float(match.group(1)) / 100), user_input)\n",
    "        user_input = self.normalize_whitespace_and_characters(user_input)\n",
    "        user_input = self.remove_sql_keywords(user_input)\n",
    "        return user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 16:45:09,486 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:09,779 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:09,824 - INFO - > Table desc str: Inventory categories: essential, non-essential, nearing obsolescence, obsolete. Ensure detailed, relevant responses and ALWAYS include numerical figures wherever possible'. Access 'supplier_name' flexibly e.g., ('%bmw%'). Use JOINs prefaced with table names for combining multiple tables. Calculate COGS as the sum of costs directly associated with goods sold. Calculate Gross Margin Percentage/Gross Margin as (Quantity Sold * Price - COGS) / Quantity Sold * Price * 100. Order months chronologically (e.g., january, february, ..., december) in query results.\n",
      "\n",
      "Table 'sales' has columns: id (INTEGER), part_number (VARCHAR), month (VARCHAR), year (INTEGER), quantity_sold (INTEGER), and foreign keys: ['part_number'] -> parts.['part_number']. The table description is: Provides time-based sales count data for individual parts. Use for part-specific sales queries. No price column\n",
      "\n",
      "Table 'parts' has columns: one_month_days_supply (FLOAT), days_of_inventory_outstanding (BIGINT), description (TEXT), roi (FLOAT), order_to_sales_ratio (FLOAT), quantity_ordered_ytd (BIGINT), supplier_name (TEXT), annual_turnover (FLOAT), special_orders_ytd (BIGINT), three_month_days_supply (FLOAT), safety_stock (BIGINT), one_month_turnover (FLOAT), annual_days_supply (FLOAT), quantity (BIGINT), inventory_category (TEXT), three_month_turnover (FLOAT), price (FLOAT), obsolescence_risk (FLOAT), reorder_point (BIGINT), cost_per_unit (BIGINT), part_number (TEXT), sell_through_rate (FLOAT), negative_on_hand (BIGINT), demand (FLOAT), months_no_sale (BIGINT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "\n",
      "Table 'parts' has columns: one_month_days_supply (FLOAT), days_of_inventory_outstanding (BIGINT), description (TEXT), roi (FLOAT), order_to_sales_ratio (FLOAT), quantity_ordered_ytd (BIGINT), supplier_name (TEXT), annual_turnover (FLOAT), special_orders_ytd (BIGINT), three_month_days_supply (FLOAT), safety_stock (BIGINT), one_month_turnover (FLOAT), annual_days_supply (FLOAT), quantity (BIGINT), inventory_category (TEXT), three_month_turnover (FLOAT), price (FLOAT), obsolescence_risk (FLOAT), reorder_point (BIGINT), cost_per_unit (BIGINT), part_number (TEXT), sell_through_rate (FLOAT), negative_on_hand (BIGINT), demand (FLOAT), months_no_sale (BIGINT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "2024-07-04 16:45:11,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:12,675 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:12,881 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:12,920 - INFO - > Table desc str: Inventory categories: essential, non-essential, nearing obsolescence, obsolete. Ensure detailed, relevant responses and ALWAYS include numerical figures wherever possible'. Access 'supplier_name' flexibly e.g., ('%bmw%'). Use JOINs prefaced with table names for combining multiple tables. Calculate COGS as the sum of costs directly associated with goods sold. Calculate Gross Margin Percentage/Gross Margin as (Quantity Sold * Price - COGS) / Quantity Sold * Price * 100. Order months chronologically (e.g., january, february, ..., december) in query results.\n",
      "\n",
      "Table 'sales' has columns: id (INTEGER), part_number (VARCHAR), month (VARCHAR), year (INTEGER), quantity_sold (INTEGER), and foreign keys: ['part_number'] -> parts.['part_number']. The table description is: Provides time-based sales count data for individual parts. Use for part-specific sales queries. No price column\n",
      "\n",
      "Table 'parts' has columns: one_month_days_supply (FLOAT), days_of_inventory_outstanding (BIGINT), description (TEXT), roi (FLOAT), order_to_sales_ratio (FLOAT), quantity_ordered_ytd (BIGINT), supplier_name (TEXT), annual_turnover (FLOAT), special_orders_ytd (BIGINT), three_month_days_supply (FLOAT), safety_stock (BIGINT), one_month_turnover (FLOAT), annual_days_supply (FLOAT), quantity (BIGINT), inventory_category (TEXT), three_month_turnover (FLOAT), price (FLOAT), obsolescence_risk (FLOAT), reorder_point (BIGINT), cost_per_unit (BIGINT), part_number (TEXT), sell_through_rate (FLOAT), negative_on_hand (BIGINT), demand (FLOAT), months_no_sale (BIGINT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "\n",
      "Table 'parts' has columns: one_month_days_supply (FLOAT), days_of_inventory_outstanding (BIGINT), description (TEXT), roi (FLOAT), order_to_sales_ratio (FLOAT), quantity_ordered_ytd (BIGINT), supplier_name (TEXT), annual_turnover (FLOAT), special_orders_ytd (BIGINT), three_month_days_supply (FLOAT), safety_stock (BIGINT), one_month_turnover (FLOAT), annual_days_supply (FLOAT), quantity (BIGINT), inventory_category (TEXT), three_month_turnover (FLOAT), price (FLOAT), obsolescence_risk (FLOAT), reorder_point (BIGINT), cost_per_unit (BIGINT), part_number (TEXT), sell_through_rate (FLOAT), negative_on_hand (BIGINT), demand (FLOAT), months_no_sale (BIGINT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "2024-07-04 16:45:14,663 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-04 16:45:15,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9b8eee27-5d93-4f40-ac56-e37e5c09bf65': {}, 'sql_query': \"SELECT p.supplier_name, SUM((s.quantity_sold * p.price) - (s.quantity_sold * p.cost_per_unit)) AS gross_profit\\nFROM sales s\\nJOIN parts p ON s.part_number = p.part_number\\nWHERE s.month = 'june' AND s.year = 2024\\nGROUP BY p.supplier_name\\nORDER BY gross_profit DESC\\nLIMIT 1;\", 'result': [('bmw group canada', 14483.460000000001)], 'col_keys': ['supplier_name', 'gross_profit']}\n",
      "In June 2024, BMW Group Canada had the highest gross profit compared to other brands.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import openai\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "class NLQueryEngine:\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        self.sql_database, self.table_schema_objs, self.obj_index = self._initialize_table_objects()\n",
    "        self.context_str_combined = self._create_context_str()\n",
    "        openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        self.query_engine = self._create_query_engine()\n",
    "\n",
    "    def _initialize_table_objects(self):\n",
    "        sql_database = SQLDatabase(self.engine, sample_rows_in_table_info=2, include_tables=['sales', 'parts'])\n",
    "        table_contexts = {\n",
    "            'sales': \"Provides time-based sales count data for individual parts. Use for part-specific sales queries. No price column\",\n",
    "            'parts': \"Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\"\n",
    "        }\n",
    "\n",
    "        table_schema_objs = [SQLTableSchema(table_name=name, context_str=context) for name, context in table_contexts.items()]\n",
    "        table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "\n",
    "        obj_index = ObjectIndex.from_objects(\n",
    "            table_schema_objs,\n",
    "            table_node_mapping,\n",
    "            VectorStoreIndex,\n",
    "        )\n",
    "        return sql_database, table_schema_objs, obj_index\n",
    "    \n",
    "    @lru_cache()\n",
    "    def _create_context_str(self):\n",
    "        context_str = (\n",
    "            \"Inventory categories: essential, non-essential, nearing obsolescence, obsolete. \"\n",
    "            \"Ensure detailed, relevant responses and ALWAYS include numerical figures wherever possible'. \"\n",
    "            \"Access 'supplier_name' flexibly e.g., ('%bmw%'). \"\n",
    "            \"Use JOINs prefaced with table names for combining multiple tables. \"\n",
    "            \"Calculate COGS as the sum of costs directly associated with goods sold. \"\n",
    "            \"Calculate Gross Margin Percentage/Gross Margin as (Quantity Sold * Price - COGS) / Quantity Sold * Price * 100. \"\n",
    "            \"Order months chronologically (e.g., january, february, ..., december) in query results.\"\n",
    "        )\n",
    "        table_context_str = self._get_table_context_str()\n",
    "        return context_str + \"\\n\\n\" + table_context_str\n",
    "    \n",
    "    @lru_cache()\n",
    "    def _get_table_context_str(self):\n",
    "        context_strs = []\n",
    "        for table_schema_obj in self.table_schema_objs:\n",
    "            table_info = self.sql_database.get_single_table_info(table_schema_obj.table_name)\n",
    "            if table_schema_obj.context_str:\n",
    "                table_info += f\" The table description is: {table_schema_obj.context_str}\"\n",
    "            context_strs.append(table_info)\n",
    "        return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "    def _create_query_engine(self):\n",
    "        return SQLTableRetrieverQueryEngine(\n",
    "            sql_database=self.sql_database,\n",
    "            table_retriever=self.obj_index.as_retriever(similarity_top_k=1),\n",
    "            synthesize_response=True,\n",
    "            llm=OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0125\"),\n",
    "            context_str_prefix=self.context_str_combined\n",
    "        )\n",
    "    \n",
    "    def query(self, user_input, return_sql=False):\n",
    "        response = self.query_engine.query(user_input)\n",
    "        if return_sql:\n",
    "            return response.metadata.get('sql_query', '')\n",
    "        return response\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_intent(user_input):\n",
    "        if any(keyword in user_input.lower() for keyword in [\"visual\", \"chart\", \"graph\", \"plot\", \"bar\", \"pie\", \"line\"]):\n",
    "            return \"visual\"\n",
    "        return \"text\"\n",
    "\n",
    "    def generate_visual(self, result_data, columns, chart_details):\n",
    "        \"\"\" Generate a visual representation based on the query results \"\"\"\n",
    "        df = pd.DataFrame(result_data, columns=columns)\n",
    "        return generate_plotly_visual(df, **chart_details)\n",
    "    \n",
    "    def extract_details(self, user_input):\n",
    "        return extract_chart_details(self, user_input)\n",
    "    \n",
    "    @lru_cache()\n",
    "    def query_visual(self, user_input):\n",
    "        \"\"\" Handle queries intended for visual representation \"\"\"\n",
    "        sql_query = self.query(user_input, return_sql=True)\n",
    "        result_data, columns = self.execute_sql_query(sql_query)\n",
    "        chart_details = self.extract_details(user_input)\n",
    "        return self.generate_visual(result_data, columns, chart_details)\n",
    "    \n",
    "    @lru_cache()\n",
    "    def query_text(self, user_input):\n",
    "        \"\"\" Handle textual queries \"\"\"\n",
    "        sql_query = self.query(user_input, return_sql=True)\n",
    "        result_data, columns = self.execute_sql_query(sql_query)\n",
    "        if len(result_data) > 5:\n",
    "            return pd.DataFrame(result_data, columns=columns)\n",
    "        return self.query(user_input)  # Direct LLM query if not enough data for a dataframe\n",
    "    \n",
    "    def execute_sql_query(self, sql_query):\n",
    "        \"\"\" Execute an SQL query and return the results and column names \"\"\"\n",
    "        with self.engine.connect() as connection:\n",
    "            result = connection.execute(text(sql_query))\n",
    "            result_data = result.fetchall()\n",
    "            columns = result.keys()\n",
    "        return result_data, columns\n",
    "\n",
    "    \n",
    "def query_output(query_engine, user_input):\n",
    "    \"\"\" Determine the intent and dispatch to the appropriate handler \"\"\"\n",
    "    intent = query_engine.parse_intent(user_input)\n",
    "    if intent == \"visual\":\n",
    "        return query_engine.query_visual(user_input)\n",
    "    else:\n",
    "        return query_engine.query_text(user_input)\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "    engine = create_engine(f\"sqlite:///{db_file_path}\")\n",
    "    query_engine = NLQueryEngine(engine)\n",
    "    processor = QueryProcessor()\n",
    "    user_input = \"what brand had the highest gross profit in June 2024?\"\n",
    "    #user_input = \"build a pie chart of each inventory catagory as a percentage of the total inventory and the total cost of each category?\"\n",
    "    #user_input = \"Build a bar chart to compare for the total sales revenue, cogs, and gross profit for 2023 versus 2024?\"\n",
    "\n",
    "    processed_input = processor.preprocess_query(user_input)  # Preprocess the user input\n",
    "\n",
    "    # Process the query with the preprocessed input\n",
    "    response = query_output(query_engine, processed_input)\n",
    "    print(response.metadata)\n",
    "    print(response)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Functions that are used to analyze inventory data and assess problem areas --> create tools from these functions\n",
    "\n",
    "##### Key Problem Areas:\n",
    "- High months no sale: stocked parts are not selling --> pricing issue, quantity issue, poor ordering, or cyclicality?\n",
    "- Improper quantity: quantity below reorder point w/ no current orders --> poor management or long lead time?\n",
    "- Large negative on hand: selling parts we dont have --> poor stocking\n",
    "- Margin/pricing issues: low margin + high sales = need to increase price and vice-versa\n",
    "- Large percentage of obsolescence: need to blow off these parts --> sell at loss to re-coup invested capital\n",
    "- Low ROI: either the parts are not selling or they are too expensive to hold in inventory and should be ordered just-in-time\n",
    "- Special orders with no sales: Could mean we arent charging the customer before ordering or special ordering parts we shouldnt\n",
    "- Stockouts of high sales volume parts: indicates a stockout of parts that have lots of sales --> poor inventory managment\n",
    "- high day supply \n",
    "- High carrying cost\n",
    "\n",
    "##### Define thresholds\n",
    "- Margin below 40% but sales greater than the avg 12 month rolling sales for non-obsolete parts\n",
    "- ROI below 25%\n",
    "- Day supply greater than 65 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your database file\n",
    "db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "# \"r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\"\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "def analyze_roi(threshold=25):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                part_number,\n",
    "                description, \n",
    "                quantity,\n",
    "                price,     \n",
    "                roi\n",
    "            FROM\n",
    "                parts p\n",
    "            WHERE roi < :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        low_roi_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return low_roi_parts\n",
    "\n",
    "def analyze_inventory():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category\n",
    "            FROM parts\n",
    "            WHERE inventory_category = 'obsolete'\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        obsolete_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return obsolete_parts\n",
    "\n",
    "def analyze_days_supply(threshold=60):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category,\n",
    "                annual_days_supply\n",
    "            FROM parts\n",
    "            WHERE inventory_category != 'obsolete'\n",
    "            AND annual_days_supply > :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        high_days_supply = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return high_days_supply \n",
    "\n",
    "def analyze_special_orders():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                p.part_number,\n",
    "                p.description,\n",
    "                p.quantity,\n",
    "                p.price,\n",
    "                p.special_orders_ytd, \n",
    "                SUM(s.quantity_sold) as total_quantity_sold\n",
    "            FROM parts p\n",
    "            JOIN sales s ON p.part_number = s.part_number\n",
    "            WHERE p.special_orders_ytd > 0\n",
    "            GROUP BY p.part_number, p.description, p.quantity, p.price, p.special_orders_ytd\n",
    "            HAVING SUM(s.quantity_sold) = 0\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        special_orders = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return special_orders\n",
    "\n",
    "def analyze_orders():\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            p.part_number,\n",
    "            p.description,\n",
    "            p.quantity,\n",
    "            p.price,\n",
    "            p.quantity_ordered_ytd,\n",
    "            s.quantity_sold\n",
    "        FROM parts p\n",
    "        JOIN sales s ON p.part_number = s.part_number\n",
    "        WHERE s.quantity_sold = 0 AND p.quantity_ordered_ytd > 0\n",
    "        \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        bad_orders = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return bad_orders\n",
    "\n",
    "def analyze_stockouts(threshold_value=10):\n",
    "    query = text(\"\"\"\n",
    "        WITH PreviousMonthSales AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month,\n",
    "                year,\n",
    "                quantity_sold,\n",
    "                LEAD(quantity_sold) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month_sales,\n",
    "                LEAD(month) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month,\n",
    "                LEAD(year) OVER (PARTITION BY part_number ORDER BY year, month) AS next_year\n",
    "            FROM sales\n",
    "        ),\n",
    "        PotentialStockouts AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month AS previous_month,\n",
    "                year AS previous_year,\n",
    "                quantity_sold AS previous_month_sales,\n",
    "                next_month,\n",
    "                next_year,\n",
    "                next_month_sales AS current_month_sales\n",
    "            FROM PreviousMonthSales\n",
    "            WHERE quantity_sold > :high_sales_threshold\n",
    "            AND (next_month_sales IS NULL OR next_month_sales = 0)\n",
    "        )\n",
    "        SELECT\n",
    "            p.part_number,\n",
    "            p.description,\n",
    "            p.quantity,\n",
    "            p.price,\n",
    "            ps.previous_month,\n",
    "            ps.previous_year,\n",
    "            ps.previous_month_sales,\n",
    "            ps.next_month,\n",
    "            ps.next_year,\n",
    "            ps.current_month_sales\n",
    "        FROM\n",
    "            parts p\n",
    "        JOIN PotentialStockouts ps ON p.part_number = ps.part_number\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {'high_sales_threshold': threshold_value})\n",
    "        result_df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return result_df\n",
    "\n",
    "def analyze_negative_on_hand():\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            part_number,\n",
    "            description,\n",
    "            quantity,\n",
    "            price, \n",
    "            negative_on_hand\n",
    "        FROM parts\n",
    "        WHERE negative_on_hand != 0\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        negative_on_hand_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return negative_on_hand_parts\n",
    "\n",
    "def analyze_reorder_point():\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            part_number,\n",
    "            description,\n",
    "            quantity,\n",
    "            price,\n",
    "            reorder_point\n",
    "        FROM parts\n",
    "        WHERE quantity < reorder_point\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        below_reorder = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return below_reorder\n",
    "\n",
    "def compile_analysis_results():\n",
    "    results = {}\n",
    "    results['low_roi_parts'] = analyze_roi()\n",
    "    results['obsolete_parts'] = analyze_inventory()\n",
    "    results['high_days_supply_parts'] = analyze_days_supply()\n",
    "    results['special_orders'] = analyze_special_orders()\n",
    "    results['potential_stockouts'] = analyze_stockouts()\n",
    "    results['negative_on_hand_parts'] = analyze_negative_on_hand()\n",
    "    results['below_reorder_point'] = analyze_reorder_point()\n",
    "    return results\n",
    "\n",
    "# Compile the analysis results\n",
    "results = compile_analysis_results()\n",
    "\n",
    "\n",
    "#need to implement the knowledge database to provide strategic advice based on the compiled analysis\n",
    "\n",
    "    \n",
    "#Other tools for the co-pilot\n",
    "\n",
    "def get_current_year_month():\n",
    "    \"\"\"\n",
    "    Get the current year and month. For temporal queries like: \"how many sales of part 123456 have sold this year so far?\"\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the current year and month.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now()\n",
    "    return current_date.year, current_date.month\n",
    "\n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month, name=\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making tools for the functions used to analyze problems in inventory ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 20:13:29,071 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Making tools from functions that analyze the data\n",
    "\n",
    "analyze_roi_tool = FunctionTool.from_defaults(fn=analyze_roi, name=\"low_roi\", description=\"Finding inventory that has a low return on investment.\")\n",
    "analyze_inventory_tool = FunctionTool.from_defaults(fn=analyze_inventory, name=\"obsolete_parts\", description=\"Finding inventory that is obsolete and has been in stock for more than six months.\")\n",
    "analyze_days_supply_tool = FunctionTool.from_defaults(fn=analyze_days_supply, name=\"high_days_supply\", description=\"Finding inventory that is of high days supply and needs a longer duration to sell.\")\n",
    "analyze_special_orders_tool = FunctionTool.from_defaults(fn=analyze_special_orders, name=\"special_orders\", description=\"Finding inventory that is specialed ordered.\")\n",
    "analyze_stockouts_tool = FunctionTool.from_defaults(fn=analyze_stockouts, name=\"potential_stockouts\", description=\"Finding inventory that may be unavailable soon.\")\n",
    "analyze_negative_on_hand_tool = FunctionTool.from_defaults(fn=analyze_negative_on_hand, name=\"negative_on_hand\", description=\"Finding inventory that needs to be ordered since there is negative on hand.\")\n",
    "analyze_reorder_point_tool = FunctionTool.from_defaults(fn=analyze_reorder_point, name='analyze_reorder_point', description='Find inventory where the quantity is less than the reorder point. Helps to identify parts that need to be reordered')\n",
    "analyze_orders_tool = FunctionTool.from_defaults(fn=analyze_orders, name='bad_orders', description=\"identifies parts that were ordered when they shouldnt have been. Either ordering obsolete parts or ordering parts that did not sell\")\n",
    "nl_to_graph_tool = FunctionTool.from_defaults(fn=query_output, name='nl_to_graph', description='generates comprehensive graphical visuals from natural language query inputs')\n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month, name=\"date\", description=\"gets the current month of the current date for temporal inventory analysis\")\n",
    "compile_analysis_results_tool = FunctionTool.from_defaults(fn=compile_analysis_results, name=\"analysis_results\", description=\"Compiling all analysis results, including parts that have a low return on investment, are obsolete, are of high days supply, are special ordered, that may stockout soon, or have negative on hand.\")\n",
    "\n",
    "all_tools = [analyze_roi_tool] + [analyze_inventory_tool] + [analyze_days_supply_tool] + [analyze_special_orders_tool] + [analyze_stockouts_tool] + [analyze_negative_on_hand_tool] + [date_tool] + [nl_to_graph_tool] + [analyze_reorder_point_tool] + [analyze_orders_tool] + [compile_analysis_results_tool]\n",
    "all_tools_map = {t.metadata.name: t for t in all_tools}\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot agent that uses tools ###\n",
    "This is the first agent that I worked on. It uses a chatbot agent and the tools from above to give answers to the user input. \n",
    "\n",
    "To incorporate the knowledge database, I created a vector store index which I used to make a query engine tool. The chatbot agent was then initialized with the function tools and the query engine tools so that it could pull information from the inventory data and the knowledge database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 20:13:32,314 - INFO - Loading all indices.\n",
      "2024-06-23 20:13:32,317 - INFO - Knowledge index loaded successfully.\n",
      "2024-06-23 20:13:42,864 - INFO - Loading all indices.\n",
      "2024-06-23 20:13:42,878 - INFO - Tools index loaded successfully.\n",
      "2024-06-23 20:13:42,878 - INFO - Both indices were loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# knowledge db and tools data\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.readers.file.base import SimpleDirectoryReader\n",
    "\n",
    "knowledge_dir = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/knowledge_database\"\n",
    "#r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\n",
    "tools_dir = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/Notebooks/tools_data\"\n",
    "#r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\"\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=knowledge_dir)\n",
    "    knowledge_index = load_index_from_storage(storage_context)\n",
    "    logging.info(\"Knowledge index loaded successfully.\")\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=tools_dir)\n",
    "    tools_index = load_index_from_storage(storage_context)\n",
    "    logging.info(\"Tools index loaded successfully.\")\n",
    "    \n",
    "    index_loaded = True\n",
    "    logging.info(\"Both indices were loaded successfully.\")\n",
    "except Exception as e:\n",
    "    index_loaded = False\n",
    "    logging.error(\"Failed to load indices: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    knowledge_docs = SimpleDirectoryReader(input_dir=knowledge_dir).load_data()\n",
    "    tools_docs = SimpleDirectoryReader(input_dir=tools_dir).load_data()\n",
    "    # build index\n",
    "    knowledge_index = VectorStoreIndex.from_documents(knowledge_docs)\n",
    "    tools_index = VectorStoreIndex.from_documents(tools_docs)\n",
    "    # persist index\n",
    "    knowledge_index.storage_context.persist(persist_dir=knowledge_dir)\n",
    "    tools_index.storage_context.persist(persist_dir=tools_dir)\n",
    "\n",
    "    # define knowledge engine\n",
    "knowledge_engine = knowledge_index.as_query_engine(similarity_top_k=3)\n",
    "tools_engine = tools_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tool from the knowledge engine\n",
    "query_engine_tools = [\n",
    "    # Query engine tool for the knowledge database\n",
    "    QueryEngineTool(\n",
    "        query_engine=knowledge_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"knowledge database\",\n",
    "            description=(\n",
    "                \"Provides detailed information about automotive parts inventory management.\"\n",
    "                \"Acts as a strategic advisor for parts managers with data driven insights\"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    # Query engine tool for the data analysis tools\n",
    "    # QueryEngineTool(\n",
    "    #     query_engine=tools_engine,\n",
    "    #     metadata=ToolMetadata(\n",
    "    #         name=\"tools_database\",\n",
    "    #         description=(\n",
    "    #             \"Provides data on dealership car parts.\"\n",
    "    #             \"Use a detailed plain text question as input to the tool.\"\n",
    "    #         )\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agent using both knowledge query engine tool and function tools\n",
    "# makes it so that the agent has access to both the knowledge database and the SQL data\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "# initialize the agent\n",
    "agent = OpenAIAgent.from_tools(query_engine_tools + all_tools, \n",
    "                               llm=OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0125\"),\n",
    "                               verbose=True)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        text_input = input(\"User: \")\n",
    "        if text_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = agent.chat(text_input)\n",
    "        print(f\"Agent: {response}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"An error occurred: %s\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different agents for each tool ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING DIFFERENT AGENTS FOR EACH TOOL\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import LlamaIndexTool\n",
    "\n",
    "crewai_tools = [LlamaIndexTool.from_tool(t) for t in all_tools + query_engine_tools]\n",
    "tools_dict_keys = [\"low roi\", \"obsolete parts\", \"high days supply\", \"special orders\", \"potential stockouts\", \"negative\", \"analysis\", 'reorder_point','orders','date', 'nl_to_graph', 'knowledge database']\n",
    "\n",
    "tools_dict = {tools_dict_keys[i]: crewai_tools[i] for i in range(len(tools_dict_keys))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating crewai tools from the function tools above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making agents for each tool and tasks that we want the agent to solve. Might be able to consolidate a few of the agents into a single one with multiple tools\n",
    "\n",
    "example:\n",
    "- Low ROI, obsolescence and high days supply are related\n",
    "- Negative on hand quantity and stockouts are related\n",
    "\n",
    "Tasks:\n",
    "1. Summarize the entire parts department displaying KPI's a couple graphs like a bar chart with gross profit, sales revenue, and cogs for each month and a pie chart that breaks down the inventory category preentage. Provide some detailed information about the parts department and return some example tabular data and maybe a csv of problem parts?\n",
    "2. Targeted analysis, provide data backed targeted responses for particular queries\n",
    "3. Strategic advice: based on the state of the inventory and the questions asked, provide data driven strategic advice on hwo to help solve or treat the problem areas\n",
    "\n",
    "2 and 3 might be able to be combined. Not sure how we would design the summary I was thinking something like a stock analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 18:33:19,914 - WARNING - Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2024-06-25 18:33:19][DEBUG]: == Working Agent: Inventory Insight Agent\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-06-25 18:33:19][INFO]: == Starting Task: Analyze the overall performance of the parts department.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 18:33:20,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-06-25 18:33:20,188 - INFO - Retrying request to /chat/completions in 0.815333 seconds\n",
      "2024-06-25 18:33:21,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-06-25 18:33:21,217 - INFO - Retrying request to /chat/completions in 1.952096 seconds\n",
      "2024-06-25 18:33:23,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mTo analyze the overall performance of the parts department, I'll need to gather data on parts with poor ROI, obsolescence, and high days supply levels. I'll start by using the tools available to collect the necessary data.\n",
      "\n",
      "Action: low_roi\n",
      "Action Input: {}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "      part_number                      description  quantity   price     roi\n",
      "0         004-153  bearing ntn 6203llu/2a 40x17x12         1    9.99 -100.00\n",
      "1        004hf113   hi-flo o-filt hon 15412-hm5-a1         1    4.99  -45.99\n",
      "2        0069925b      universal cruise control 1\"         1   18.99    0.11\n",
      "3         01-0140                  valve stem seal         8    5.99 -100.00\n",
      "4        01-04249    shinko 804 big block 90/90-21         1  104.99 -100.00\n",
      "...           ...                              ...       ...     ...     ...\n",
      "11187      yb5l-b          yb5l-b yumicron 12 volt         1   73.99 -100.00\n",
      "11188    ytx14-bs   ytx14-bs maintenance free batt         1  154.99  -28.23\n",
      "11189    ytx7l-bs             ytx7l-bs w/acid apck         1  112.99  -14.17\n",
      "11190     z1-link         timing chain master link         1   24.95 -100.00\n",
      "11191   ze53-0130                           risers         1   59.99 -100.00\n",
      "\n",
      "[11192 rows x 5 columns]\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 18:33:24,853 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-06-25 18:33:24,854 - INFO - Retrying request to /chat/completions in 0.820135 seconds\n",
      "2024-06-25 18:33:25,893 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-06-25 18:33:25,894 - INFO - Retrying request to /chat/completions in 1.628315 seconds\n",
      "2024-06-25 18:33:27,746 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 55\u001b[0m\n\u001b[1;32m     48\u001b[0m crew \u001b[38;5;241m=\u001b[39m Crew(\n\u001b[1;32m     49\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[inventory_insight_agent, operational_improvement_agent, strategic_advisory_agent],\n\u001b[1;32m     50\u001b[0m     tasks\u001b[38;5;241m=\u001b[39m[comprehensive_analysis_task, targeted_operational_analysis_task, strategic_management_advice_task],\n\u001b[1;32m     51\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# RUN AGENTS TO SOLVE TASKS\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###########################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/crew.py:271\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    268\u001b[0m metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 271\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# type: ignore # Unpacking a string is disallowed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     result, manager_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/crew.py:357\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_log_file:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_handler\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    354\u001b[0m         agent\u001b[38;5;241m=\u001b[39mrole, task\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mdescription, status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m     )\n\u001b[0;32m--> 357\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39masync_execution:\n\u001b[1;32m    360\u001b[0m     task_output \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/task.py:187\u001b[0m, in \u001b[0;36mTask.execute\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/task.py:196\u001b[0m, in \u001b[0;36mTask._execute\u001b[0;34m(self, agent, task, context, tools)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, task, context, tools):\n\u001b[0;32m--> 196\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     exported_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    205\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m    206\u001b[0m         exported_output\u001b[38;5;241m=\u001b[39mexported_output,\n\u001b[1;32m    207\u001b[0m         raw_output\u001b[38;5;241m=\u001b[39mresult,\n\u001b[1;32m    208\u001b[0m         agent\u001b[38;5;241m=\u001b[39magent\u001b[38;5;241m.\u001b[39mrole,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/agent.py:243\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description \u001b[38;5;241m=\u001b[39m render_text_description(\n\u001b[1;32m    240\u001b[0m     parsed_tools)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__tools_names(parsed_tools)\n\u001b[0;32m--> 243\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rpm:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller\u001b[38;5;241m.\u001b[39mstop_rpm_counter()\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/agents/executor.py:128\u001b[0m, in \u001b[0;36mCrewAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, time_elapsed):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit():\n\u001b[0;32m--> 128\u001b[0m         next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_callback:\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_callback(next_step_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/crewai/agents/executor.py:192\u001b[0m, in \u001b[0;36mCrewAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    189\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore #  Incompatible types in assignment (expression has type \"AgentAction | AgentFinish | list[AgentAction]\", variable has type \"AgentAction\")\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain/agents/agent.py:397\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2869\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2871\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2872\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2874\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2875\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:2862\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2859\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2860\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2863\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2864\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2865\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2866\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:1881\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1881\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mnext\u001b[39m, iterator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1882\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1883\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:2826\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2818\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2819\u001b[0m         final_pipeline,\n\u001b[1;32m   2820\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2823\u001b[0m         ),\n\u001b[1;32m   2824\u001b[0m     )\n\u001b[0;32m-> 2826\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_pipeline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:1282\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m final: Input\n\u001b[1;32m   1280\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:4736\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   4731\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4732\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   4733\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4734\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4735\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 4736\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   4737\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4738\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4739\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4740\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/runnables/base.py:1300\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1300\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:249\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    244\u001b[0m         e,\n\u001b[1;32m    245\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    246\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    247\u001b[0m         ),\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:229\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:480\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    479\u001b[0m default_chunk_class \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/partsmatch/lib/python3.11/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Define agents with consolidated roles\n",
    "inventory_insight_agent = Agent(\n",
    "    role=\"Inventory Insight Agent\",\n",
    "    goal=\"Analyze and provide insights on parts inventory, focusing on parts with poor ROI, obsolescence, and high days supply levels.\",\n",
    "    backstory=\"You are a data-driven AI analyst specializing in inventory management, aimed at optimizing inventory levels and reducing waste.\",\n",
    "    tools=[tools_dict['low roi'], tools_dict['obsolete parts'], tools_dict['high days supply']],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "operational_improvement_agent = Agent(\n",
    "    role=\"Order management Improvement Agent\",\n",
    "    goal=\"Identify mistakes in parts ordering or poor ordering decision making as well as identifying parts that should be reordered/replenished.\",\n",
    "    backstory='You are an AI order management advisor that ensures correct ordering practices for the parts manager ',\n",
    "    tools=[tools_dict['special orders'], tools_dict['potential stockouts'], tools_dict['negative'], tools_dict['reorder_point'], tools_dict['orders']],\n",
    "    verbose=True, \n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "strategic_advisory_agent = Agent(\n",
    "    role=\"Strategic Advisory Agent\",\n",
    "    goal=\"Provide data-driven strategic advice to parts managers to improve operational efficeincy. Provided highly targeted stratehic advice backed by data from the database\", \n",
    "    backstory=\"You are an AI parts department consultant that provides strategic advice to parts managers\",\n",
    "    tools=[tools_dict['analysis'], tools_dict['knowledge database']],\n",
    "    verbose=True,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Initialize tasks\n",
    "comprehensive_analysis_task = Task(\n",
    "    description=\"Analyze the overall performance of the parts department.\",\n",
    "    agent=inventory_insight_agent,\n",
    "    expected_output=\"A comprehensive dashboard with visuals and data tables.\"\n",
    ")\n",
    "\n",
    "targeted_operational_analysis_task = Task(\n",
    "    description=\"Provide specific analyses on operational issues.\",\n",
    "    agent=operational_improvement_agent,\n",
    "    expected_output=\"Detailed operational reports with data-backed recommendations.\"\n",
    ")\n",
    "\n",
    "strategic_management_advice_task = Task(\n",
    "    description=\"Provide strategic inventory management advice.\",\n",
    "    agent=strategic_advisory_agent,\n",
    "    expected_output=\"Strategic advice and actionable steps for inventory management.\"\n",
    ")\n",
    "\n",
    "# INITIALIZE CREW WITH AGENTS NEEDED FOR THE TASKS\n",
    "crew = Crew(\n",
    "    agents=[inventory_insight_agent, operational_improvement_agent, strategic_advisory_agent],\n",
    "    tasks=[comprehensive_analysis_task, targeted_operational_analysis_task, strategic_management_advice_task],\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# RUN AGENTS TO SOLVE TASKS\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"###########################\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a crew with agents needed for the tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from the agents trying to solve example tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for the hybrid query engine ###\n",
    "(this wasn't working but idk if we'll use it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:47:59,415 - WARNING - Ignoring wrong pointing object 22 0 (offset 0)\n",
      "2024-06-19 09:47:59,519 - WARNING - Ignoring wrong pointing object 20 0 (offset 0)\n",
      "2024-06-19 09:47:59,595 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:47:59,596 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:47:59,598 - WARNING - Ignoring wrong pointing object 13 0 (offset 0)\n",
      "2024-06-19 09:47:59,599 - WARNING - Ignoring wrong pointing object 16 0 (offset 0)\n",
      "2024-06-19 09:47:59,600 - WARNING - Ignoring wrong pointing object 18 0 (offset 0)\n",
      "2024-06-19 09:47:59,601 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:47:59,602 - WARNING - Ignoring wrong pointing object 29 0 (offset 0)\n",
      "2024-06-19 09:47:59,862 - WARNING - Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2024-06-19 09:47:59,863 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:47:59,864 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:47:59,864 - WARNING - Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2024-06-19 09:48:00,033 - WARNING - Ignoring wrong pointing object 9 0 (offset 0)\n",
      "2024-06-19 09:48:00,034 - WARNING - Ignoring wrong pointing object 11 0 (offset 0)\n",
      "2024-06-19 09:48:00,036 - WARNING - Ignoring wrong pointing object 17 0 (offset 0)\n",
      "2024-06-19 09:48:00,037 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:48:00,158 - WARNING - Ignoring wrong pointing object 17 0 (offset 0)\n",
      "2024-06-19 09:48:00,260 - WARNING - Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2024-06-19 09:48:00,261 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:48:00,262 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:48:00,263 - WARNING - Ignoring wrong pointing object 12 0 (offset 0)\n",
      "2024-06-19 09:48:00,263 - WARNING - Ignoring wrong pointing object 15 0 (offset 0)\n",
      "2024-06-19 09:48:00,264 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:48:00,690 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:48:00,692 - WARNING - Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2024-06-19 09:48:03,913 - WARNING - Ignoring wrong pointing object 19 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 7 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 14 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 16 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 30 0 (offset 0)\n",
      "2024-06-19 09:48:03,977 - WARNING - Ignoring wrong pointing object 32 0 (offset 0)\n",
      "2024-06-19 09:48:03,978 - WARNING - Ignoring wrong pointing object 34 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\\~$le_inventory_trend.docx with error: File is not a zip file. Skipping...\n",
      "Failed to load file C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\\~$le_stock.docx with error: File is not a zip file. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR HYBRID QUERY ENGINE THAT WASN'T WORKING\n",
    "# file reader for knowledge database\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\"\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir)\n",
    "knowledge_documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data from function tools\n",
    "tools_analysis_results = compile_analysis_results()\n",
    "\n",
    "# Converting dataframes into csvs\n",
    "for key in tools_analysis_results.keys():\n",
    "    base_path = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\\\\\"\n",
    "    file_name = key + \".csv\"\n",
    "    tools_analysis_results[key].to_csv(base_path + file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in csvs into documents\n",
    "tools_documents_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\"\n",
    "reader = SimpleDirectoryReader(input_dir=tools_documents_dir)\n",
    "tools_documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data into json document\n",
    "# json.dump(tools_analysis_results, out_file, indent=6)\n",
    "\n",
    "# out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json reader for tools data\n",
    "# from llama_index.readers.json import JSONReader\n",
    "# json_file = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\index\\tools_data.json\"\n",
    "# reader = JSONReader()\n",
    "# keyword_documents = reader.load_data(input_file=json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "# from llama_index.core.node_parser import JSONNodeParser\n",
    "\n",
    "# parser = JSONNodeParser()\n",
    "knowledge_nodes = Settings.node_parser.get_nodes_from_documents(knowledge_documents)\n",
    "tools_nodes = Settings.node_parser.get_nodes_from_documents(tools_documents)\n",
    "# json_nodes = parser.get_nodes_from_documents(json_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_storage_context = StorageContext.from_defaults()\n",
    "vector_storage_context.docstore.add_documents(knowledge_nodes)\n",
    "\n",
    "keyword_storage_context = StorageContext.from_defaults()\n",
    "keyword_storage_context.docstore.add_documents(tools_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:56:28,715 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:30,032 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:32,444 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:33,751 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:35,667 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:36,865 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:38,465 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:40,552 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:40,967 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_CBEventType.EMBEDDING ->  1.383237 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.35824 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.356682 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.1506 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.095168 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.173531 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.530428 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.184701 seconds\n",
      "    |_CBEventType.EMBEDDING ->  0.181473 seconds\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleKeywordTableIndex, VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(tools_nodes, storage_context=keyword_storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(tools_nodes, storage_context=keyword_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import QueryBundle\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "# import NodeWithScore\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "# Retrievers\n",
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    "    KeywordTableSimpleRetriever,\n",
    ")\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both semantic search and hybrid search.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        keyword_retriever: KeywordTableSimpleRetriever,\n",
    "        mode: str = \"AND\",\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._keyword_retriever = keyword_retriever\n",
    "        if mode not in (\"AND\", \"OR\"):\n",
    "            raise ValueError(\"Invalid mode.\")\n",
    "        self._mode = mode\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        keyword_nodes = self._keyword_retriever.retrieve(query_bundle)\n",
    "\n",
    "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "        keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
    "\n",
    "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "        combined_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
    "\n",
    "        if self._mode == \"AND\":\n",
    "            retrieve_ids = vector_ids.intersection(keyword_ids)\n",
    "        else:\n",
    "            retrieve_ids = vector_ids.union(keyword_ids)\n",
    "\n",
    "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
    "        return retrieve_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# define custom retriever\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=2)\n",
    "keyword_retriever = KeywordTableSimpleRetriever(index=keyword_index)\n",
    "custom_retriever = CustomRetriever(vector_retriever, keyword_retriever)\n",
    "\n",
    "# define response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "custom_query_engine = RetrieverQueryEngine(\n",
    "    retriever=custom_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# vector query engine\n",
    "vector_query_engine = RetrieverQueryEngine(\n",
    "    retriever=vector_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "# keyword query engine\n",
    "keyword_query_engine = RetrieverQueryEngine(\n",
    "    retriever=keyword_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:57:01,516 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:57:01,602 - INFO - > Starting query: What are some parts from the roi csv\n",
      "2024-06-19 09:57:01,602 - INFO - query keywords: ['roi', 'parts', 'csv']\n",
      "2024-06-19 09:57:01,602 - INFO - > Extracted keywords: ['parts']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_CBEventType.QUERY ->  0.284426 seconds\n",
      "**********\n",
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "response = custom_query_engine.query(\"What are some parts from the roi csv\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PartsWise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
