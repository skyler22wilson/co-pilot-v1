{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0.0, 0.0, 6, 0.0, 0, -100.0, 'obsolete', 1, 0, 0.0, 1.0, 0.0, 13, 0.0, 0.0, 'bearing ntn 6203llu/2a 40x17x12', '004-153', 9.99, 0, 0.0, 'motovan', 0.0)\n",
      "(0, 0, 0.0, 0.0, 3, 1.0, 0, -45.99, 'non-essential', 1, 0, 0.0052214272, 0.75, 1.0, 5, 0.0, 0.0, 'hi-flo o-filt hon 15412-hm5-a1', '004hf113', 4.99, 0, 360.0, 'thibault canada', 0.0)\n",
      "(0, 0, 0.0, 0.0, 9, 1.0, 0, 0.11, 'nearing_obsolete', 1, 0, 0.2523689809, 0.7756696429, 1.0, 8, 0.0, 0.0, 'new style universal cruise ctr', '0069922bc', 18.99, 0, 360.0, 'thibault canada', 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sales', 'parts']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text, inspect\n",
    "from llama_index.core import SQLDatabase\n",
    "# Path to your database file\n",
    "db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "\n",
    "# Create an engine instance\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection using raw SQL\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM parts LIMIT 3\"))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "tables = ['sales', 'parts']\n",
    "# sql_database = SQLDatabase(engine, include_tables=tables,sample_rows_in_table_info=5)\n",
    "sql_database = SQLDatabase(engine, sample_rows_in_table_info=2)#by default3 (actually)\n",
    "list(sql_database._all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import html, dcc\n",
    "import dash_ag_grid as dag\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "def create_table(df):\n",
    "    # Define the column structure for the AG Grid\n",
    "    column_defs = [\n",
    "        {'headerName': col, 'field': col} for col in df.columns\n",
    "    ]\n",
    "    rowData = df.to_dict('records')  # Convert DataFrame to a list of dictionaries for rowData\n",
    "\n",
    "    grid_options = {\n",
    "         'pagination': True,\n",
    "         'paginationPageSize': 10,\n",
    "         'paginationPageSizeSelector': [10, 25, 50, 100, 500, 1000],\n",
    "         'enablePivot': True,\n",
    "         'enableSorting': True,\n",
    "         'enableFilter': True,\n",
    "\n",
    "    }\n",
    "    col_def = {\"editable\": True, \"filter\": True}\n",
    "    \n",
    "    return dag.AgGrid(\n",
    "        id='table-fig',\n",
    "        dashGridOptions=grid_options,\n",
    "        columnDefs=column_defs,\n",
    "        defaultColDef=col_def,\n",
    "        rowData=rowData,  # Use rowData here instead of data\n",
    "        exportDataAsCsv=True,  # Enable CSV export feature\n",
    "        columnSize=\"autoSize\",\n",
    "        csvExportParams={\n",
    "            \"fileName\": \"partswise_data.csv\",  # Set the filename for the exported CSV file\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import plotly.express as px\n",
    "import openai\n",
    "from llama_index.core import SQLDatabase, PromptTemplate, VectorStoreIndex\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "class NLQueryEngine:\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        self.sql_database, self.table_schema_objs, self.obj_index = self._initialize_table_objects()\n",
    "        self.context_str_combined = self._create_context_str()\n",
    "        openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        self.query_engine = self._create_query_engine()\n",
    "\n",
    "    def _initialize_table_objects(self):\n",
    "        sql_database = SQLDatabase(self.engine, sample_rows_in_table_info=2, include_tables=['sales', 'parts'])\n",
    "        table_contexts = {\n",
    "            'sales': \"Provides time-based sales data for individual parts. Use for part-specific sales queries.\",\n",
    "            'parts': \"Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\"\n",
    "        }\n",
    "        \n",
    "        table_schema_objs = [SQLTableSchema(table_name=name, context_str=context) for name, context in table_contexts.items()]\n",
    "        table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "        \n",
    "        obj_index = ObjectIndex.from_objects(\n",
    "            table_schema_objs,\n",
    "            table_node_mapping,\n",
    "            VectorStoreIndex,\n",
    "        )\n",
    "        return sql_database, table_schema_objs, obj_index\n",
    "\n",
    "    def _create_context_str(self):\n",
    "        context_str = (\n",
    "            \"Inventory categories: essential, non-essential, nearing obsolescence, obsolete. \"\n",
    "            \"Ensure detailed, relevant responses, including 'supplier_name', 'price', and 'quantity'. \"\n",
    "            \"Access 'supplier_name' flexibly e.g., ('%bmw'). \"\n",
    "            \"Convert percentages to decimals (e.g., '50%' as '0.5'). \"\n",
    "            \"Use JOINs prefaced with table names for combining multiple tables. \"\n",
    "            \"Calculate COGS as the sum of costs directly associated with goods sold. \"\n",
    "            \"Calculate Gross Margin Percentage/Gross Margin as (Sales Revenue - COGS) / Sales Revenue * 100.\"\n",
    "            \"Order months chronologically like a calendar (e.g., January, February, ..., December) in query results \"\n",
    "        )\n",
    "        table_context_str = self._get_table_context_str()\n",
    "        return context_str + \"\\n\\n\" + table_context_str\n",
    "\n",
    "    def _get_table_context_str(self):\n",
    "        context_strs = []\n",
    "        for table_schema_obj in self.table_schema_objs:\n",
    "            table_info = self.sql_database.get_single_table_info(table_schema_obj.table_name)\n",
    "            if table_schema_obj.context_str:\n",
    "                table_info += f\" The table description is: {table_schema_obj.context_str}\"\n",
    "            context_strs.append(table_info)\n",
    "        return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "    def _create_query_engine(self):\n",
    "        return SQLTableRetrieverQueryEngine(\n",
    "            sql_database=self.sql_database,\n",
    "            table_retriever=self.obj_index.as_retriever(similarity_top_k=1),\n",
    "            synthesize_response=True,\n",
    "            llm=OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0125\"),\n",
    "            context_str_prefix=self.context_str_combined\n",
    "        )\n",
    "\n",
    "    def query(self, user_input):\n",
    "        response = self.query_engine.query(user_input)\n",
    "        return response\n",
    "\n",
    "def process_user_input_to_sql(query_engine, user_input):\n",
    "    response = query_engine.query(user_input)\n",
    "    sql_query = response.metadata.get('sql_query', '').replace('\\n', ' ').replace('\\r', ' ').strip().lower()\n",
    "    logging.info(f\"SQL QUERY after adjustment: {sql_query}\")\n",
    "    if sql_query.startswith('sql'):\n",
    "        sql_query = sql_query[3:].strip()\n",
    "    logging.info(f\"SQL: {sql_query}\")\n",
    "    return sql_query\n",
    "\n",
    "def output_sql_query_to_sentence(query_engine, sql_query):\n",
    "    response = query_engine.query(sql_query)\n",
    "    return str(response)\n",
    "\n",
    "def output_sql_query_to_df(result_data, columns):\n",
    "    logging.info(f\"Query Result Data: {result_data}\")\n",
    "    logging.info(f\"Columns: {columns}\")\n",
    "    return pd.DataFrame(result_data, columns=columns)\n",
    "\n",
    "def generate_plotly_visual(df, chart_type, title, x_axis_label, y_axis_label):\n",
    "    if chart_type == \"line\":\n",
    "        fig = px.line(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "    elif chart_type == \"bar\":\n",
    "        fig = go.Figure()\n",
    "        for col in df.columns[1:]:\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=df[df.columns[0]], \n",
    "                y=df[col],\n",
    "                name=col\n",
    "            ))\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis_title=x_axis_label,\n",
    "            yaxis_title=y_axis_label,\n",
    "            barmode='group'\n",
    "        )\n",
    "    elif chart_type == \"scatter\":\n",
    "        fig = px.scatter(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "    elif chart_type == \"pie\":\n",
    "        fig = px.pie(df, names=df.columns[0], values=df.columns[1], title=title)\n",
    "    else:\n",
    "        fig = px.scatter(df, x=df.columns[0], y=df.columns[1:], title=title)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': title,\n",
    "            'y':0.9,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "        },\n",
    "        xaxis_title=x_axis_label,\n",
    "        yaxis_title=y_axis_label,\n",
    "        hovermode=\"closest\",\n",
    "        plot_bgcolor='white',  \n",
    "        paper_bgcolor='white',  \n",
    "        font=dict(\n",
    "            family=\"Arial, sans-serif\",\n",
    "            size=12,\n",
    "            color=\"Gray\"\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            linecolor='Gray',\n",
    "            linewidth=1,\n",
    "            tickformat=',',  \n",
    "            title_standoff=10,\n",
    "            tickfont=dict(size=14),  \n",
    "            titlefont=dict(size=16)  \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showline=True,\n",
    "            linecolor='Gray',\n",
    "            linewidth=1,\n",
    "            tickformat=',',\n",
    "            title_standoff=10,\n",
    "            tickfont=dict(size=14), \n",
    "            titlefont=dict(size=16) \n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=0.5,\n",
    "            y=-0.2,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "            orientation='h',  # Horizontal legend at the bottom\n",
    "            bgcolor='rgba(255,255,255,0.8)',  # Transparent white background for legend\n",
    "            bordercolor='Gray',\n",
    "            borderwidth=1,\n",
    "            font=dict(size=16) \n",
    "        ),\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Adjust margins\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def extract_chart_details(query_engine, user_input):\n",
    "    text_qa_template_str = (\n",
    "        \"Given the query: '{query_str}', extract the following details:\\n\"\n",
    "        \"1. Chart type (e.g., bar, line, pie, etc.)\\n\"\n",
    "        \"2. Title for the chart\\n\"\n",
    "        \"3. X-axis label\\n\"\n",
    "        \"4. Y-axis label\\n\"\n",
    "        \"\\n\"\n",
    "        \"Provide the details in the following format:\\n\"\n",
    "        \"Chart type: <type>\\n\"\n",
    "        \"Title: <title>\\n\"\n",
    "        \"X-axis label: <label>\\n\"\n",
    "        \"Y-axis label: <label>\\n\"\n",
    "    )\n",
    "    text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "    \n",
    "    prompt = text_qa_template.format(query_str=user_input)\n",
    "    response = query_engine.query(prompt)\n",
    "    logging.info(f\"LLM Response: {response.response.strip()}\")\n",
    "    response_text = response.response.strip()\n",
    "    lines = response_text.split('\\n')\n",
    "    \n",
    "    chart_type = \"bar\"  # Default value\n",
    "    title = \"Generated Chart\"\n",
    "    x_axis_label = \"X Axis\"\n",
    "    y_axis_label = \"Y Axis\"\n",
    "\n",
    "    for line in lines:\n",
    "        if \"Chart type:\" in line:\n",
    "            chart_type = line.split(\":\", 1)[1].strip().lower()\n",
    "        elif \"Title:\" in line:\n",
    "            title = line.split(\":\", 1)[1].strip()\n",
    "        elif \"X-axis label:\" in line:\n",
    "            x_axis_label = line.split(\":\", 1)[1].strip()\n",
    "        elif \"Y-axis label:\" in line:\n",
    "            y_axis_label = line.split(\":\", 1)[1].strip()\n",
    "    \n",
    "    return chart_type, title, x_axis_label, y_axis_label\n",
    "\n",
    "def output_sql_query_to_graph(result_data, columns, chart_type, title, x_axis_label, y_axis_label):\n",
    "    logging.info(f\"Query Result Data: {result_data}\")\n",
    "    logging.info(f\"Columns: {columns}\")\n",
    "    result_df = pd.DataFrame(result_data, columns=columns)\n",
    "    fig = generate_plotly_visual(result_df, chart_type, title, x_axis_label, y_axis_label)\n",
    "    fig.show()\n",
    "\n",
    "def parse_intent(user_input):\n",
    "    if any(keyword in user_input.lower() for keyword in [\"visual\", \"chart\", \"graph\", \"plot\", \"bar\", \"pie\"]):\n",
    "        return \"visual\"\n",
    "    return \"text\"\n",
    "\n",
    "def query_output(query_engine, user_input):\n",
    "    intent = parse_intent(user_input)\n",
    "    sql_query = process_user_input_to_sql(query_engine, user_input)\n",
    "    logging.info(f\"SQL QUERY Output: {sql_query}\")\n",
    "\n",
    "    with query_engine.engine.connect() as connection:\n",
    "        result = connection.execute(text(sql_query))\n",
    "        result_data = result.fetchall()\n",
    "        columns = result.keys()\n",
    "        logging.info(f\"Executed SQL Query: {sql_query}\")\n",
    "        logging.info(f\"Resulting Data: {result_data}\")\n",
    "\n",
    "        if intent == \"visual\":\n",
    "            chart_type, title, x_axis_label, y_axis_label = extract_chart_details(query_engine, user_input)\n",
    "            output_sql_query_to_graph(result_data, columns, chart_type, title, x_axis_label, y_axis_label)\n",
    "        else:\n",
    "            if len(result_data) >= 5:\n",
    "                df = output_sql_query_to_df(result_data, columns)\n",
    "                return html.Div(create_table(df))\n",
    "            return output_sql_query_to_sentence(query_engine, sql_query)\n",
    "\n",
    "def main():\n",
    "    db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "    engine = create_engine(f\"sqlite:///{db_file_path}\")\n",
    "    query_engine = NLQueryEngine(engine)\n",
    "    user_input = \"Create a table of all of my parts that are not yet obsolete but have an obsolescence risk of greater than 75 percent\"\n",
    "    response = query_output(query_engine, user_input)\n",
    "    response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $8327.22 in September 2023\n",
    "# $8327.22 in January 2024\n",
    "# $8,327.22 in March 2024\n",
    "\n",
    "#Something is going on here --> this is wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Functions that are used to analyze inventory data and assess problem areas --> create tools from these functions\n",
    "\n",
    "##### Key Problem Areas:\n",
    "- High months no sale: stocked parts are not selling --> pricing issue, quantity issue, poor ordering, or cyclicality?\n",
    "- Improper quantity: quantity below reorder point w/ no current orders --> poor management or long lead time?\n",
    "- Large negative on hand: selling parts we dont have --> poor stocking\n",
    "- Margin/pricing issues: low margin + high sales = need to increase price and vice-versa\n",
    "- Large percentage of obsolescence: need to blow off these parts --> sell at loss to re-coup invested capital\n",
    "- Low ROI: either the parts are not selling or they are too expensive to hold in inventory and should be ordered just-in-time\n",
    "- Special orders with no sales: Could mean we arent charging the customer before ordering or special ordering parts we shouldnt\n",
    "- Stockouts of high sales volume parts: indicates a stockout of parts that have lots of sales --> poor inventory managment\n",
    "- high day supply \n",
    "- High carrying cost\n",
    "\n",
    "##### Define thresholds\n",
    "- Margin below 40% but sales greater than the avg 12 month rolling sales for non-obsolete parts\n",
    "- ROI below 25%\n",
    "- Day supply greater than 65 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knowledge database build\n",
    "#design: problem --> solution --> reference(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your database file\n",
    "db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "def analyze_roi(threshold=25):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                part_number,\n",
    "                description, \n",
    "                quantity,\n",
    "                price,     \n",
    "                roi\n",
    "            FROM\n",
    "                parts p\n",
    "            WHERE roi < :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        low_roi_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return low_roi_parts\n",
    "\n",
    "def analyze_inventory():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category\n",
    "            FROM parts\n",
    "            WHERE inventory_category = 'obsolete'\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        obsolete_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return obsolete_parts\n",
    "\n",
    "def analyze_days_supply(threshold=60):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category,\n",
    "                annual_days_supply\n",
    "            FROM parts\n",
    "            WHERE inventory_category != 'obsolete'\n",
    "            AND annual_days_supply > :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        high_days_supply = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return high_days_supply \n",
    "\n",
    "def analyze_special_orders():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                p.part_number,\n",
    "                p.description,\n",
    "                p.quantity,\n",
    "                p.price,\n",
    "                p.special_orders_ytd, \n",
    "                SUM(s.quantity_sold) as total_quantity_sold\n",
    "            FROM parts p\n",
    "            JOIN sales s ON p.part_number = s.part_number\n",
    "            WHERE p.special_orders_ytd > 0\n",
    "            GROUP BY p.part_number, p.description, p.quantity, p.price, p.special_orders_ytd\n",
    "            HAVING SUM(s.quantity_sold) = 0\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        special_orders = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return special_orders\n",
    "\n",
    "def analyze_stockouts(threshold_value=10):\n",
    "    query = text(\"\"\"\n",
    "        WITH PreviousMonthSales AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month,\n",
    "                year,\n",
    "                quantity_sold,\n",
    "                LEAD(quantity_sold) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month_sales,\n",
    "                LEAD(month) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month,\n",
    "                LEAD(year) OVER (PARTITION BY part_number ORDER BY year, month) AS next_year\n",
    "            FROM sales\n",
    "        ),\n",
    "        PotentialStockouts AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month AS previous_month,\n",
    "                year AS previous_year,\n",
    "                quantity_sold AS previous_month_sales,\n",
    "                next_month,\n",
    "                next_year,\n",
    "                next_month_sales AS current_month_sales\n",
    "            FROM PreviousMonthSales\n",
    "            WHERE quantity_sold > :high_sales_threshold\n",
    "            AND (next_month_sales IS NULL OR next_month_sales = 0)\n",
    "        )\n",
    "        SELECT\n",
    "            p.part_number,\n",
    "            p.description,\n",
    "            p.quantity,\n",
    "            p.price,\n",
    "            ps.previous_month,\n",
    "            ps.previous_year,\n",
    "            ps.previous_month_sales,\n",
    "            ps.next_month,\n",
    "            ps.next_year,\n",
    "            ps.current_month_sales\n",
    "        FROM\n",
    "            parts p\n",
    "        JOIN PotentialStockouts ps ON p.part_number = ps.part_number\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {'high_sales_threshold': threshold_value})\n",
    "        result_df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return result_df\n",
    "\n",
    "def analyze_negative_on_hand():\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            part_number,\n",
    "            description,\n",
    "            quantity,\n",
    "            price, \n",
    "            negative_on_hand\n",
    "        FROM parts\n",
    "        WHERE negative_on_hand != 0\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        negative_on_hand_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return negative_on_hand_parts\n",
    "\n",
    "def compile_analysis_results():\n",
    "    results = {}\n",
    "    results['low_roi_parts'] = analyze_roi()\n",
    "    results['obsolete_parts'] = analyze_inventory()\n",
    "    results['high_days_supply_parts'] = analyze_days_supply()\n",
    "    results['special_orders'] = analyze_special_orders()\n",
    "    results['potential_stockouts'] = analyze_stockouts()\n",
    "    results['negative_on_hand_parts'] = analyze_negative_on_hand()\n",
    "    return results\n",
    "\n",
    "# Compile the analysis results\n",
    "results = compile_analysis_results()\n",
    "\n",
    "\n",
    "#need to implement the knowledge database to provide strategic advice based on the compiled analysis\n",
    "\n",
    "    \n",
    "#Other tools for the co-pilot\n",
    "\n",
    "def get_current_year_month():\n",
    "    \"\"\"\n",
    "    Get the current year and month. For temporal queries like: \"how many sales of part 123456 have sold this year so far?\"\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the current year and month.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now()\n",
    "    return current_date.year, current_date.month\n",
    "\n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id part_number     month  year  quantity_sold\n",
      "0            1     004-153   january  2023              0\n",
      "1            2    004hf113   january  2023              0\n",
      "2            3   0069922bc   january  2023              0\n",
      "3            4    0069925b   january  2023              0\n",
      "4            5     01-0140   january  2023              0\n",
      "...        ...         ...       ...   ...            ...\n",
      "283147  283148    yt12b-bs  december  2024              0\n",
      "283148  283149    ytx14-bs  december  2024              0\n",
      "283149  283150    ytx7l-bs  december  2024              0\n",
      "283150  283151     z1-link  december  2024              0\n",
      "283151  283152   ze53-0130  december  2024              0\n",
      "\n",
      "[283152 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# *** For testing queries only ***\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your database file\n",
    "db_file_path = \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "\n",
    "# Create an engine instance\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "#threshold_value = 25  # Define your threshold value here\n",
    "\n",
    "# Define the query\n",
    "query = text(\"\"\"\n",
    "    select * from sales\n",
    "\"\"\")\n",
    "\n",
    "# Execute the query within a managed connection\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(query)\n",
    "    result_df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "# Print the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "\n",
    "def get_current_year_month():\n",
    "    \"\"\"\n",
    "    Get the current year and month.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the current year and month.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now()\n",
    "    return current_date.year, current_date.month\n",
    "\n",
    " \n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month)\n",
    "    \n",
    "'''\n",
    "Will incorporate this later, once the marketplace is finished. Will be used to execute bulk actions within the maarketplace like \n",
    "getting all obsolete inventory from a particular brand, reducing the price by 50% and preparing it for bulk upload onto the marketplace\n",
    "\n",
    "# Define metadata for your tool\n",
    "bulk_action_metadata = ToolMetadata(\n",
    "    name=\"bulk_action_tool\",\n",
    "    description=(\"Agent that executes bulk actions like price adjustments on\"\n",
    "                \" retrieved data that satisfies provided conditions about the parts.\"\n",
    "                \"Use a detailed plain text question as input to the tool.\")\n",
    ")\n",
    "\n",
    "# Set up the QueryEngineTool with the sql_agent and its metadata\n",
    "bulk_action_tool = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=engine,\n",
    "        metadata=bulk_action_metadata,\n",
    "    ),\n",
    "]\n",
    "'''\n",
    "\n",
    "# This will be adjusted to incorporate the knowledge database when I finish accumulating it\n",
    "# Need to figure out if i can use multiple engines for these\n",
    "inventory_analyzer_metadata = ToolMetadata (\n",
    "    name=\"inventory_analyzer_tool\",\n",
    "    description=(\"Agent that analyzes inventory data including 'months_no_sale', 'obsolescence_risk', \"\n",
    "                 \"'sales_to_stock_ratio', 'rolling_12_month_sales','rolling_3_month_sales', and '12_month_turnover' \"\n",
    "                 \"and makes suggestions to reduce and prevent obsolescence.\"\n",
    "                 \"Use a detailed plain text question as input to the tool.\")\n",
    ")\n",
    "\n",
    "inventory_analyzer_tool = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=engine,\n",
    "        metadata=inventory_analyzer_metadata,\n",
    "    )\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PartsWise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
