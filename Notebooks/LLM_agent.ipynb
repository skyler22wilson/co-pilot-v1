{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('motovan', 0, 0.0, 1.0, 0, -100.0, 0.0, 13, 0, 0, 0.0, 0.0, 9.99, 6, 'obsolete', 1, 0.0, 0.0, '004-153', 0, 0.0, 0.0, 'bearing ntn 6203llu/2a 40x17x12', 0.0)\n",
      "('thibault canada', 0, 1.0, 0.75, 0, -45.99, 0.0052214272, 5, 0, 0, 0.0, 0.0, 4.99, 3, 'non-essential', 1, 0.0, 0.0, '004hf113', 0, 0.0, 360.0, 'hi-flo o-filt hon 15412-hm5-a1', 1.0)\n",
      "('thibault canada', 0, 1.0, 0.7756696429, 0, 0.11, 0.2523689809, 8, 0, 0, 0.0, 0.0, 18.99, 9, 'nearing_obsolete', 1, 0.0, 0.0, '0069922bc', 0, 0.0, 360.0, 'new style universal cruise ctr', 1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['parts', 'sales']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text, inspect\n",
    "from llama_index.core import SQLDatabase\n",
    "# Path to your database file\n",
    "db_file_path =  r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "\n",
    "# Create an engine instance\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection using raw SQL\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM parts LIMIT 3\"))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "tables = ['sales', 'parts']\n",
    "# sql_database = SQLDatabase(engine, include_tables=tables,sample_rows_in_table_info=5)\n",
    "sql_database = SQLDatabase(engine, sample_rows_in_table_info=2)#by default3 (actually)\n",
    "list(sql_database._all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   table_name              column_name\n",
      "0       parts            supplier_name\n",
      "1       parts     quantity_ordered_ytd\n",
      "2       parts     sales_to_stock_ratio\n",
      "3       parts        obsolescence_risk\n",
      "4       parts       special_orders_ytd\n",
      "5       parts                      roi\n",
      "6       parts                   demand\n",
      "7       parts           months_no_sale\n",
      "8       parts             safety_stock\n",
      "9       parts            reorder_point\n",
      "10      parts  three_month_days_supply\n",
      "11      parts       one_month_turnover\n",
      "12      parts                    price\n",
      "13      parts            cost_per_unit\n",
      "14      parts       inventory_category\n",
      "15      parts                 quantity\n",
      "16      parts    one_month_days_supply\n",
      "17      parts     three_month_turnover\n",
      "18      parts              part_number\n",
      "19      parts         negative_on_hand\n",
      "20      parts     order_to_sales_ratio\n",
      "21      parts       annual_days_supply\n",
      "22      parts              description\n",
      "23      parts          annual_turnover\n",
      "24      sales                       id\n",
      "25      sales              part_number\n",
      "26      sales                    month\n",
      "27      sales                     year\n",
      "28      sales            quantity_sold\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Database Path\n",
    "db_file_path =  r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "#  \"r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\"\n",
    "engine = create_engine(f\"sqlite:///{db_file_path}\")\n",
    "\n",
    "# Create an inspector object\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Create a DataFrame to hold table and column information\n",
    "table_column_df = pd.DataFrame(columns=[\"table_name\", \"column_name\"])\n",
    "\n",
    "# Iterate through the table names and collect column info\n",
    "for table_name in table_names:\n",
    "    table_cols = inspector.get_columns(table_name)  # Use inspector to get columns\n",
    "    table_col_tuples = [(table_name, col['name']) for col in table_cols]\n",
    "    temp_df = pd.DataFrame(table_col_tuples, columns=[\"table_name\", \"column_name\"])\n",
    "    table_column_df = pd.concat([table_column_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Display the table and column names\n",
    "print(table_column_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will likely need to break this up into 3 components:\n",
    "1. Targeted responses\n",
    "2. Tabular data\n",
    "3. Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 12:22:49,960 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:50,560 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:50,564 - INFO - > Table desc str: Inventory categories: essential, non-essential, nearing obsolescence, obsolete. Ensure detailed, relevant responses, including 'supplier_name', 'price', and 'quantity'. Access 'supplier_name' flexibly e.g., ('%bmw'). Convert percentages to decimals (e.g., '50%' as '0.5'). Use JOINs prefaced with table names for combining multiple tables. Calculate COGS as the sum of costs directly associated with goods sold. Calculate Gross Margin Percentage/Gross Margin as (Sales Revenue - COGS) / Sales Revenue * 100.\n",
      "\n",
      "Table 'sales' has columns: id (INTEGER), part_number (VARCHAR), month (VARCHAR), year (INTEGER), quantity_sold (INTEGER), and foreign keys: ['part_number'] -> parts.['part_number']. The table description is: Provides time-based sales quantity data for individual parts. Use for part-specific sales queries. NO PRICE COLUMNS\n",
      "\n",
      "Table 'parts' has columns: supplier_name (TEXT), quantity_ordered_ytd (BIGINT), sales_to_stock_ratio (FLOAT), obsolescence_risk (FLOAT), special_orders_ytd (BIGINT), roi (FLOAT), demand (FLOAT), months_no_sale (BIGINT), safety_stock (BIGINT), reorder_point (BIGINT), three_month_days_supply (FLOAT), one_month_turnover (FLOAT), price (FLOAT), cost_per_unit (BIGINT), inventory_category (TEXT), quantity (BIGINT), one_month_days_supply (FLOAT), three_month_turnover (FLOAT), part_number (TEXT), negative_on_hand (BIGINT), order_to_sales_ratio (FLOAT), annual_days_supply (FLOAT), description (TEXT), annual_turnover (FLOAT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "\n",
      "Table 'parts' has columns: supplier_name (TEXT), quantity_ordered_ytd (BIGINT), sales_to_stock_ratio (FLOAT), obsolescence_risk (FLOAT), special_orders_ytd (BIGINT), roi (FLOAT), demand (FLOAT), months_no_sale (BIGINT), safety_stock (BIGINT), reorder_point (BIGINT), three_month_days_supply (FLOAT), one_month_turnover (FLOAT), price (FLOAT), cost_per_unit (BIGINT), inventory_category (TEXT), quantity (BIGINT), one_month_days_supply (FLOAT), three_month_turnover (FLOAT), part_number (TEXT), negative_on_hand (BIGINT), order_to_sales_ratio (FLOAT), annual_days_supply (FLOAT), description (TEXT), annual_turnover (FLOAT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "2024-06-24 12:22:53,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:54,785 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:54,788 - INFO - SQL QUERY after adjustment: select p.supplier_name, avg((s.quantity_sold * p.price - s.quantity_sold * p.cost_per_unit) / (s.quantity_sold * p.price) * 100) as avg_gross_margin_percentage from sales s join parts p on s.part_number = p.part_number where s.month = 'june' and s.year = 2023 group by p.supplier_name order by avg_gross_margin_percentage desc limit 1;\n",
      "2024-06-24 12:22:54,788 - INFO - SQL: select p.supplier_name, avg((s.quantity_sold * p.price - s.quantity_sold * p.cost_per_unit) / (s.quantity_sold * p.price) * 100) as avg_gross_margin_percentage from sales s join parts p on s.part_number = p.part_number where s.month = 'june' and s.year = 2023 group by p.supplier_name order by avg_gross_margin_percentage desc limit 1;\n",
      "2024-06-24 12:22:54,789 - INFO - SQL QUERY Output: select p.supplier_name, avg((s.quantity_sold * p.price - s.quantity_sold * p.cost_per_unit) / (s.quantity_sold * p.price) * 100) as avg_gross_margin_percentage from sales s join parts p on s.part_number = p.part_number where s.month = 'june' and s.year = 2023 group by p.supplier_name order by avg_gross_margin_percentage desc limit 1;\n",
      "2024-06-24 12:22:54,827 - INFO - Query Result Data: [('lordco', 73.28805624788089)]\n",
      "2024-06-24 12:22:54,944 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:54,947 - INFO - > Table desc str: Inventory categories: essential, non-essential, nearing obsolescence, obsolete. Ensure detailed, relevant responses, including 'supplier_name', 'price', and 'quantity'. Access 'supplier_name' flexibly e.g., ('%bmw'). Convert percentages to decimals (e.g., '50%' as '0.5'). Use JOINs prefaced with table names for combining multiple tables. Calculate COGS as the sum of costs directly associated with goods sold. Calculate Gross Margin Percentage/Gross Margin as (Sales Revenue - COGS) / Sales Revenue * 100.\n",
      "\n",
      "Table 'sales' has columns: id (INTEGER), part_number (VARCHAR), month (VARCHAR), year (INTEGER), quantity_sold (INTEGER), and foreign keys: ['part_number'] -> parts.['part_number']. The table description is: Provides time-based sales quantity data for individual parts. Use for part-specific sales queries. NO PRICE COLUMNS\n",
      "\n",
      "Table 'parts' has columns: supplier_name (TEXT), quantity_ordered_ytd (BIGINT), sales_to_stock_ratio (FLOAT), obsolescence_risk (FLOAT), special_orders_ytd (BIGINT), roi (FLOAT), demand (FLOAT), months_no_sale (BIGINT), safety_stock (BIGINT), reorder_point (BIGINT), three_month_days_supply (FLOAT), one_month_turnover (FLOAT), price (FLOAT), cost_per_unit (BIGINT), inventory_category (TEXT), quantity (BIGINT), one_month_days_supply (FLOAT), three_month_turnover (FLOAT), part_number (TEXT), negative_on_hand (BIGINT), order_to_sales_ratio (FLOAT), annual_days_supply (FLOAT), description (TEXT), annual_turnover (FLOAT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "\n",
      "Table 'parts' has columns: supplier_name (TEXT), quantity_ordered_ytd (BIGINT), sales_to_stock_ratio (FLOAT), obsolescence_risk (FLOAT), special_orders_ytd (BIGINT), roi (FLOAT), demand (FLOAT), months_no_sale (BIGINT), safety_stock (BIGINT), reorder_point (BIGINT), three_month_days_supply (FLOAT), one_month_turnover (FLOAT), price (FLOAT), cost_per_unit (BIGINT), inventory_category (TEXT), quantity (BIGINT), one_month_days_supply (FLOAT), three_month_turnover (FLOAT), part_number (TEXT), negative_on_hand (BIGINT), order_to_sales_ratio (FLOAT), annual_days_supply (FLOAT), description (TEXT), annual_turnover (FLOAT), and foreign keys: . The table description is: Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\n",
      "2024-06-24 12:22:57,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 12:22:58,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The supplier with the highest average gross margin percentage in June 2023 is Lordco with an average of 73.29%.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import pandas as pd\n",
    "import logging\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Database Path\n",
    "db_file_path =  r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_file_path}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def setup_nlsql_query_engine():\n",
    "    # Function to initialize SQLDatabase and table objects\n",
    "    def initialize_table_objects():\n",
    "        sql_database = SQLDatabase(engine, sample_rows_in_table_info=2, include_tables=['sales', 'parts'])\n",
    "        parts_context = \"Provides detailed inventory data for individual parts. Use part-specific queries. Combine with 'sales' tables for temporal financial performance\"\n",
    "        sales_context = \"Provides time-based sales quantity data for individual parts. Use for part-specific sales queries. NO PRICE COLUMNS\"\n",
    "\n",
    "        table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "        table_schema_objs = [\n",
    "            SQLTableSchema(table_name='sales', context_str=sales_context),\n",
    "            SQLTableSchema(table_name='parts', context_str=parts_context),\n",
    "        ]\n",
    "        obj_index = ObjectIndex.from_objects(\n",
    "            table_schema_objs,\n",
    "            table_node_mapping,\n",
    "            VectorStoreIndex,\n",
    "        )\n",
    "        return sql_database, table_schema_objs, obj_index\n",
    "\n",
    "\n",
    "    # Function to generate table context string\n",
    "    def get_table_context_str(sql_database, table_schema_objs):\n",
    "        context_strs = []\n",
    "        for table_schema_obj in table_schema_objs:\n",
    "            table_info = sql_database.get_single_table_info(table_schema_obj.table_name)\n",
    "            if table_schema_obj.context_str:\n",
    "                table_opt_context = \" The table description is: \"\n",
    "                table_opt_context += table_schema_obj.context_str\n",
    "                table_info += table_opt_context\n",
    "            context_strs.append(table_info)\n",
    "        return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "\n",
    "    # Initialize table objects and get table context string\n",
    "    sql_database, table_schema_objs, obj_index = initialize_table_objects()\n",
    "    table_context_str = get_table_context_str(sql_database, table_schema_objs)\n",
    "\n",
    "    # General Context String\n",
    "    context_str = (\n",
    "    \"Inventory categories: essential, non-essential, nearing obsolescence, obsolete. \"\n",
    "    \"Ensure detailed, relevant responses, including 'supplier_name', 'price', and 'quantity'. \"\n",
    "    \"Access 'supplier_name' flexibly e.g., ('%bmw'). \"\n",
    "    \"Convert percentages to decimals (e.g., '50%' as '0.5'). \"\n",
    "    \"Use JOINs prefaced with table names for combining multiple tables. \"\n",
    "    \"Calculate COGS as the sum of costs directly associated with goods sold. \"\n",
    "    \"Calculate Gross Margin Percentage/Gross Margin as (Sales Revenue - COGS) / Sales Revenue * 100.\"\n",
    ")\n",
    "\n",
    "    # Combine Table Contexts\n",
    "    context_str_combined = context_str + \"\\n\\n\" + table_context_str\n",
    "\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]  # Replace with your OpenAI API key\n",
    "    query_engine = SQLTableRetrieverQueryEngine(\n",
    "        sql_database=sql_database,\n",
    "        table_retriever=obj_index.as_retriever(similarity_top_k=1),\n",
    "        synthesize_response=True,\n",
    "        llm=OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0125\"),\n",
    "        context_str_prefix=context_str_combined\n",
    "    )\n",
    "    return query_engine\n",
    "\n",
    "query_engine = setup_nlsql_query_engine()\n",
    "\n",
    "def process_user_input_to_sql(user_input):\n",
    "    response = query_engine.query(user_input)\n",
    "    sql_query = response.metadata.get('sql_query', '').replace('\\n', ' ').replace('\\r', ' ').strip().lower()\n",
    "    logging.info(f\"SQL QUERY after adjustment: {sql_query}\")\n",
    "    if sql_query.startswith('sql'):\n",
    "        sql_query = sql_query[3:].strip()\n",
    "    logging.info(f\"SQL: {sql_query}\")\n",
    "    return sql_query\n",
    "\n",
    "# This function decides the output format based on whether the SQL query contains aggregation functions\n",
    "def query_output(user_input):\n",
    "    sql_query = process_user_input_to_sql(user_input)\n",
    "    logging.info(f\"SQL QUERY Output: {sql_query}\")\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(sql_query))\n",
    "        result_data = result.fetchall()  # Fetch data once\n",
    "        logging.info(f\"Query Result Data: {result_data}\")\n",
    "        if len(result_data) >= 5:\n",
    "            result_df = pd.DataFrame(result_data, columns=result.keys())\n",
    "            return result_df\n",
    "        else:\n",
    "            # In this case, no table data is available, hence set 'has_data' to False\n",
    "            response = query_engine.query(sql_query)\n",
    "            return str(response)\n",
    "def main():\n",
    "    user_input = \"what brand has the highest average gross margin percentage in June 2023?\"\n",
    "    response = query_output(user_input)\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Functions that are used to analyze inventory data and assess problem areas --> create tools from these functions\n",
    "\n",
    "##### Key Problem Areas:\n",
    "- High months no sale: stocked parts are not selling --> pricing issue, quantity issue, poor ordering, or cyclicality?\n",
    "- Improper quantity: quantity below reorder point w/ no current orders --> poor management or long lead time?\n",
    "- Large negative on hand: selling parts we dont have --> poor stocking\n",
    "- Margin/pricing issues: low margin + high sales = need to increase price and vice-versa\n",
    "- Large percentage of obsolescence: need to blow off these parts --> sell at loss to re-coup invested capital\n",
    "- Low ROI: either the parts are not selling or they are too expensive to hold in inventory and should be ordered just-in-time\n",
    "- Special orders with no sales: Could mean we arent charging the customer before ordering or special ordering parts we shouldnt\n",
    "- Stockouts of high sales volume parts: indicates a stockout of parts that have lots of sales --> poor inventory managment\n",
    "- high day supply \n",
    "- High carrying cost\n",
    "\n",
    "##### Define thresholds\n",
    "- Margin below 40% but sales greater than the avg 12 month rolling sales for non-obsolete parts\n",
    "- ROI below 25%\n",
    "- Day supply greater than 65 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your database file\n",
    "db_file_path =  r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/databases/partswise_island_moto.db\"\n",
    "# \"r\"C:\\Users\\vivia\\co-pilot-v1\\data\\databases\\partswise_island_moto.db\"\"\n",
    "connection_string = f\"sqlite:///{db_file_path}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "def analyze_roi(threshold=25):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                part_number,\n",
    "                description, \n",
    "                quantity,\n",
    "                price,     \n",
    "                roi\n",
    "            FROM\n",
    "                parts p\n",
    "            WHERE roi < :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        low_roi_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return low_roi_parts\n",
    "\n",
    "def analyze_inventory():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category\n",
    "            FROM parts\n",
    "            WHERE inventory_category = 'obsolete'\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        obsolete_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return obsolete_parts\n",
    "\n",
    "def analyze_days_supply(threshold=60):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                part_number,\n",
    "                description,\n",
    "                quantity,\n",
    "                price,\n",
    "                inventory_category,\n",
    "                annual_days_supply\n",
    "            FROM parts\n",
    "            WHERE inventory_category != 'obsolete'\n",
    "            AND annual_days_supply > :threshold\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {'threshold': threshold})\n",
    "        high_days_supply = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return high_days_supply \n",
    "\n",
    "def analyze_special_orders():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT\n",
    "                p.part_number,\n",
    "                p.description,\n",
    "                p.quantity,\n",
    "                p.price,\n",
    "                p.special_orders_ytd, \n",
    "                SUM(s.quantity_sold) as total_quantity_sold\n",
    "            FROM parts p\n",
    "            JOIN sales s ON p.part_number = s.part_number\n",
    "            WHERE p.special_orders_ytd > 0\n",
    "            GROUP BY p.part_number, p.description, p.quantity, p.price, p.special_orders_ytd\n",
    "            HAVING SUM(s.quantity_sold) = 0\n",
    "        \"\"\")\n",
    "        result = connection.execute(query)\n",
    "        special_orders = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return special_orders\n",
    "\n",
    "def analyze_stockouts(threshold_value=10):\n",
    "    query = text(\"\"\"\n",
    "        WITH PreviousMonthSales AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month,\n",
    "                year,\n",
    "                quantity_sold,\n",
    "                LEAD(quantity_sold) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month_sales,\n",
    "                LEAD(month) OVER (PARTITION BY part_number ORDER BY year, month) AS next_month,\n",
    "                LEAD(year) OVER (PARTITION BY part_number ORDER BY year, month) AS next_year\n",
    "            FROM sales\n",
    "        ),\n",
    "        PotentialStockouts AS (\n",
    "            SELECT\n",
    "                part_number,\n",
    "                month AS previous_month,\n",
    "                year AS previous_year,\n",
    "                quantity_sold AS previous_month_sales,\n",
    "                next_month,\n",
    "                next_year,\n",
    "                next_month_sales AS current_month_sales\n",
    "            FROM PreviousMonthSales\n",
    "            WHERE quantity_sold > :high_sales_threshold\n",
    "            AND (next_month_sales IS NULL OR next_month_sales = 0)\n",
    "        )\n",
    "        SELECT\n",
    "            p.part_number,\n",
    "            p.description,\n",
    "            p.quantity,\n",
    "            p.price,\n",
    "            ps.previous_month,\n",
    "            ps.previous_year,\n",
    "            ps.previous_month_sales,\n",
    "            ps.next_month,\n",
    "            ps.next_year,\n",
    "            ps.current_month_sales\n",
    "        FROM\n",
    "            parts p\n",
    "        JOIN PotentialStockouts ps ON p.part_number = ps.part_number\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {'high_sales_threshold': threshold_value})\n",
    "        result_df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return result_df\n",
    "\n",
    "def analyze_negative_on_hand():\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            part_number,\n",
    "            description,\n",
    "            quantity,\n",
    "            price, \n",
    "            negative_on_hand\n",
    "        FROM parts\n",
    "        WHERE negative_on_hand != 0\n",
    "    \"\"\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        negative_on_hand_parts = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return negative_on_hand_parts\n",
    "\n",
    "def compile_analysis_results():\n",
    "    results = {}\n",
    "    results['low_roi_parts'] = analyze_roi()\n",
    "    results['obsolete_parts'] = analyze_inventory()\n",
    "    results['high_days_supply_parts'] = analyze_days_supply()\n",
    "    results['special_orders'] = analyze_special_orders()\n",
    "    results['potential_stockouts'] = analyze_stockouts()\n",
    "    results['negative_on_hand_parts'] = analyze_negative_on_hand()\n",
    "    return results\n",
    "\n",
    "# Compile the analysis results\n",
    "results = compile_analysis_results()\n",
    "\n",
    "\n",
    "#need to implement the knowledge database to provide strategic advice based on the compiled analysis\n",
    "\n",
    "    \n",
    "#Other tools for the co-pilot\n",
    "\n",
    "def get_current_year_month():\n",
    "    \"\"\"\n",
    "    Get the current year and month. For temporal queries like: \"how many sales of part 123456 have sold this year so far?\"\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the current year and month.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now()\n",
    "    return current_date.year, current_date.month\n",
    "\n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month, name=\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making tools for the functions used to analyze problems in inventory ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 12:34:08,534 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Making tools from functions that analyze the data\n",
    "\n",
    "analyze_roi_tool = FunctionTool.from_defaults(fn=analyze_roi, name=\"low_roi\", description=\"Finding inventory that has a low return on investment.\")\n",
    "analyze_inventory_tool = FunctionTool.from_defaults(fn=analyze_inventory, name=\"obsolete_parts\", description=\"Finding inventory that is obsolete and has been in stock for more than six months.\")\n",
    "analyze_days_supply_tool = FunctionTool.from_defaults(fn=analyze_days_supply, name=\"high_days_supply\", description=\"Finding inventory that is of high days supply and needs a longer duration to sell.\")\n",
    "analyze_special_orders_tool = FunctionTool.from_defaults(fn=analyze_special_orders, name=\"special_orders\", description=\"Finding inventory that is specialed ordered.\")\n",
    "analyze_stockouts_tool = FunctionTool.from_defaults(fn=analyze_stockouts, name=\"potential_stockouts\", description=\"Finding inventory that may be unavailable soon.\")\n",
    "analyze_negative_on_hand_tool = FunctionTool.from_defaults(fn=analyze_negative_on_hand, name=\"negative_on_hand\", description=\"Finding inventory that needs to be ordered since there is negative on hand.\")\n",
    "compile_analysis_results_tool = FunctionTool.from_defaults(fn=compile_analysis_results, name=\"analysis_results\", description=\"Compiling all analysis results, including parts that have a low return on investment, are obsolete, are of high days supply, are special ordered, that may stockout soon, or have negative on hand.\")\n",
    "nl_to_graph_tool = FunctionTool.from_defaults(fn=query_output, name='nl_to_graph', description='generates comprehensive graphical visuals from natural language query inputs')\n",
    "date_tool = FunctionTool.from_defaults(fn=get_current_year_month, name=\"date\", description=\"gets the current month of the current date for temporal inventory analysis\")\n",
    "\n",
    "all_tools = [analyze_roi_tool] + [analyze_inventory_tool] + [analyze_days_supply_tool] + [analyze_special_orders_tool] + [analyze_stockouts_tool] + [analyze_negative_on_hand_tool] + [compile_analysis_results_tool] + [date_tool] + [nl_to_graph_tool]\n",
    "all_tools_map = {t.metadata.name: t for t in all_tools}\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot agent that uses tools ###\n",
    "This is the first agent that I worked on. It uses a chatbot agent and the tools from above to give answers to the user input. \n",
    "\n",
    "To incorporate the knowledge database, I created a vector store index which I used to make a query engine tool. The chatbot agent was then initialized with the function tools and the query engine tools so that it could pull information from the inventory data and the knowledge database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 12:34:14,497 - INFO - Loading all indices.\n",
      "2024-06-24 12:34:14,501 - INFO - Knowledge index loaded successfully.\n",
      "2024-06-24 12:34:22,745 - INFO - Loading all indices.\n",
      "2024-06-24 12:34:22,759 - INFO - Tools index loaded successfully.\n",
      "2024-06-24 12:34:22,760 - INFO - Both indices were loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# knowledge db and tools data\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.readers.file.base import SimpleDirectoryReader\n",
    "\n",
    "knowledge_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/data/knowledge_database\"\n",
    "\n",
    "tools_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\"\n",
    "# \"/Users/skylerwilson/Desktop/PartsWise/co-pilot-v1/Notebooks/tools_data\"\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=knowledge_dir)\n",
    "    knowledge_index = load_index_from_storage(storage_context)\n",
    "    logging.info(\"Knowledge index loaded successfully.\")\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=tools_dir)\n",
    "    tools_index = load_index_from_storage(storage_context)\n",
    "    logging.info(\"Tools index loaded successfully.\")\n",
    "    \n",
    "    index_loaded = True\n",
    "    logging.info(\"Both indices were loaded successfully.\")\n",
    "except Exception as e:\n",
    "    index_loaded = False\n",
    "    logging.error(\"Failed to load indices: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    knowledge_docs = SimpleDirectoryReader(input_dir=knowledge_dir).load_data()\n",
    "    tools_docs = SimpleDirectoryReader(input_dir=tools_dir).load_data()\n",
    "    # build index\n",
    "    knowledge_index = VectorStoreIndex.from_documents(knowledge_docs)\n",
    "    tools_index = VectorStoreIndex.from_documents(tools_docs)\n",
    "    # persist index\n",
    "    knowledge_index.storage_context.persist(persist_dir=knowledge_dir)\n",
    "    tools_index.storage_context.persist(persist_dir=tools_dir)\n",
    "\n",
    "    # define knowledge engine\n",
    "knowledge_engine = knowledge_index.as_query_engine(similarity_top_k=3)\n",
    "tools_engine = tools_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tool from the knowledge engine\n",
    "query_engine_tools = [\n",
    "    # Query engine tool for the knowledge database\n",
    "    QueryEngineTool(\n",
    "        query_engine=knowledge_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"knowledge_database\",\n",
    "            description=(\n",
    "                \"Provides detailed information about automotive parts inventory management.\"\n",
    "                \"Acts as a strategic advisor for parts managers with data driven insights\"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    # Query engine tool for the data analysis tools\n",
    "    # QueryEngineTool(\n",
    "    #     query_engine=tools_engine,\n",
    "    #     metadata=ToolMetadata(\n",
    "    #         name=\"tools_database\",\n",
    "    #         description=(\n",
    "    #             \"Provides data on dealership car parts.\"\n",
    "    #             \"Use a detailed plain text question as input to the tool.\"\n",
    "    #         )\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agent using both knowledge query engine tool and function tools\n",
    "# makes it so that the agent has access to both the knowledge database and the SQL data\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "# initialize the agent\n",
    "agent = OpenAIAgent.from_tools(query_engine_tools + all_tools, \n",
    "                               llm=OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0125\"),\n",
    "                               verbose=True)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        text_input = input(\"User: \")\n",
    "        if text_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = agent.chat(text_input)\n",
    "        print(f\"Agent: {response}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"An error occurred: %s\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different agents for each tool ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING DIFFERENT AGENTS FOR EACH TOOL\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import LlamaIndexTool, DirectoryReadTool, FileReadTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating crewai tools from the function tools above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crewai_tools = [LlamaIndexTool.from_tool(t) for t in all_tools]\n",
    "tools_dict_keys = [\"low roi\", \"obsolete parts\", \"high days supply\", \"special orders\", \"potential stockouts\", \"negative\", \"analysis\", 'date', 'nl_to_graph']\n",
    "\n",
    "tools_dict = {tools_dict_keys[i]: crewai_tools[i] for i in range(len(tools_dict_keys))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_tool = DirectoryReadTool(knowledge_dir)\n",
    "file_tool = FileReadTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making agents for each tool and tasks that we want the agent to solve. Might be able to consolidate a few of the agents into a single one with multiple tools\n",
    "\n",
    "example:\n",
    "- Low ROI, obsolescence and high days supply are related\n",
    "- Negative on hand quantity and stockouts are related\n",
    "\n",
    "Tasks:\n",
    "1. Summarize the entire parts department displaying KPI's a couple graphs like a bar chart with gross profit, sales revenue, and cogs for each month and a pie chart that breaks down the inventory category preentage. Provide some detailed information about the parts department and return some example tabular data and maybe a csv of problem parts?\n",
    "2. Targeted analysis, provide data backed targeted responses for particular queries\n",
    "3. Strategic advice: based on the state of the inventory and the questions asked, provide data driven strategic advice on hwo to help solve or treat the problem areas\n",
    "\n",
    "2 and 3 might be able to be combined. Not sure how we would design the summary I was thinking something like a stock analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING AGENTS FOR EACH TOOL\n",
    "# low_roi_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of parts inventory that has a low return on investment (roi).\",\n",
    "#     backstory=\"\"\"You are a parts manager and are trying to find the parts in your inventory that have a low return on investment for better inventory management.\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['low roi']],\n",
    "# )\n",
    "\n",
    "# obsolete_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of inventory that is obsolete.\",\n",
    "#     backstory=\"\"\"You are a parts manager and are trying to find the parts in your inventory that are obsolete (6 months or older) for better inventory management.\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['obsolete parts']],\n",
    "# )\n",
    "\n",
    "# high_days_supply_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of inventory that has a high days supply.\",\n",
    "#     backstory=\"\"\"You are a parts manager and are trying to find the parts in your inventory that have a high days supply and are likely overstocked and will become obsolete or are already obsolete.\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['high days supply']],\n",
    "# )\n",
    "\n",
    "problem_parts_agent = Agent(\n",
    "    role=\"Inventory analyst\",\n",
    "    goal=\"Find problem parts that are taking up inventory space and a parts manager will want to get rid of.\",\n",
    "    backstory=\"\"\"You are an analyst looking at a parts department to determine which parts are costing the department money\n",
    "                    because the parts are taking up space on the shelf. You find the problems in the department and use data \n",
    "                    to back up your claims. \"\"\",\n",
    "    verbose=False,\n",
    "    tools=[tools_dict['low roi'], tools_dict['obsolete parts'], tools_dict['high days supply']]\n",
    ")\n",
    "\n",
    "special_orders_agent = Agent(\n",
    "    role=\"Inventory analyst\",\n",
    "    goal= \"Give analysis of inventory that is special ordered.\",\n",
    "    backstory=\"\"\"You are a parts manager and are trying to find the parts in your inventory that have many special orders which may lead to increased idle or obsolete stock for better inventory management.\"\"\",\n",
    "    verbose=False,\n",
    "    tools=[tools_dict['special orders']],\n",
    ")\n",
    "\n",
    "# stockouts_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of inventory that has had a stockout that has affected sales.\",\n",
    "#     backstory=\"\"\"You are a parts manager and are trying to find the parts in your inventory that have had a stock out resulting in a period of time with no sales follwoing months of consistently high sales.\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['potential stockouts']],\n",
    "# )\n",
    "\n",
    "# negative_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of inventory that have a negative quantity.\",\n",
    "#     backstory=\"\"\"You are a parts manager and are trying to find the negative on hand parts meaning a customer purchased a part not in inventory which suggests higher demand than anticipated and an occurance of a stockout .\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['negative']],\n",
    "# )\n",
    "\n",
    "reorder_parts_agent = Agent(\n",
    "    role=\"Inventory analyst\",\n",
    "    goal=\"Find parts that are in high demand\",\n",
    "    backstory=\"\"\"You are a parts manager and are trying to find the parts that you need to order more of which \n",
    "                include parts that have a negative quantity on hand or are likely to stock out.\n",
    "                These are parts that you are low on or need to order soon and could be profiting from more. \"\"\",\n",
    "    tools=[tools_dict['negative'], tools_dict['potential stockouts']]\n",
    ")\n",
    "\n",
    "# analysis_agent = Agent(\n",
    "#     role=\"Inventory analyst\",\n",
    "#     goal= \"Give analysis of inventory problems, including parts that have a low return on investment, are obsolete, take a long time to sell, have high special ordered, or have a negative quantity on hand.\",\n",
    "#     backstory=\"\"\"You are a parts manager and are looking for any potential issues in your inventory.\"\"\",\n",
    "#     verbose=False,\n",
    "#     tools=[tools_dict['analysis']],\n",
    "# )\n",
    "\n",
    "# INITIALIZE AGENT FOR THE KNOWLEDGE DATABASE\n",
    "knowledge_agent = Agent(\n",
    "    role=\"Inventory advisor\",\n",
    "    goal=\"Help parts manager by using the data from other tools and using the knowledge database to give advice on how to manage inventory better. Act as a strategic advisor providing data driven insights\",\n",
    "    backstory=\"\"\"You are an inventory expert trying to help the parts manager fix their inventory problems.\"\"\",\n",
    "    verbose=False,\n",
    "    allow_delegation=False\n",
    ")\n",
    "graph_agent = Agent(\n",
    "    role=\"Inventory analyst\",\n",
    "    goal=\"Help parts managers understand their data through intuative visuals and graphs that provide visual context to their parts data\",\n",
    "    backstory=\"You generate intuitive graphs from user queries that help parts managers understand their data better\",\n",
    "    verbose=False,\n",
    "    allow_delegation=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# INITIALIZE TASKS\n",
    "# task1 = Task(\n",
    "#     description=\"\"\"Give a general overview of problems in the parts department using the data provided.\"\"\",\n",
    "#     expected_output=\"A bulleted list of problems in the inventory\",\n",
    "#     agent = analysis_agent,\n",
    "# )\n",
    "\n",
    "identify_problems_task = Task(\n",
    "    description=\"\"\"Give an analysis of the problem parts in the parts department inventory.\n",
    "                    The parts manager wants a condensed overview of the problem parts in their department\n",
    "                    with data to back up the claims. Run statistics on the data that you find.\"\"\",\n",
    "    expected_output=\"A bulleted list of the top ten problem parts in the department that are costing them money.\",\n",
    "    agent = problem_parts_agent,\n",
    ")\n",
    "\n",
    "identify_reorders_task = Task(\n",
    "    description=\"\"\"Give an analysis of parts in your department that are in high demand. These are parts\n",
    "                    that a parts manager will want to order more of because they are in low or negative stock. A parts\n",
    "                    manager could profit by ordering more of these parts and selling them. \"\"\",\n",
    "    expected_output=\"A bulleted list of the top ten parts that are in high demand and should be reordered\",\n",
    "    agent = reorder_parts_agent,\n",
    ")\n",
    "\n",
    "fix_problem_parts_task = Task(\n",
    "    description=\"\"\"Using the list of problem parts in the inventory, give advice on how to solve major inventory problems.\n",
    "                    These problems have to do with parts that have been on the shelf for too long. The parts manager is trying\n",
    "                    to get rid of these parts.\"\"\",\n",
    "    expected_output=\"A paragraph on how to deal with the problem parts in inventory that have been sitting on the shelf for too long and data to back up your claims\",\n",
    "    agent=knowledge_agent,\n",
    ")\n",
    "\n",
    "fix_reorders_task = Task(\n",
    "    description=\"\"\"Using the list of parts that are in high demand, give advice on how to handle these parts.\n",
    "                    These problems have to do with parts may be low in stock and the parts manager is missng out on \n",
    "                    potential profits. \"\"\",\n",
    "    expected_output=\"A paragraph on how to deal with managing parts that are in high demand and data to back up your claims.\",\n",
    "    agent=knowledge_agent,\n",
    ")\n",
    "\n",
    "graph_task = Task(\n",
    "    description=\"\"\"Provide visuals for overall parts department performance.\"\"\",\n",
    "    expected_output=\"two or 3 graphs representing key performance indicators like inventory category percentage, gross profit, sales revenue and cogs, and brand based analysis\",\n",
    "    agent=graph_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a crew with agents needed for the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 17:51:33,348 - WARNING - Overriding of current TracerProvider is not allowed\n",
      "2024-06-24 17:51:33,361 - WARNING - Overriding of current TracerProvider is not allowed\n",
      "2024-06-24 17:51:33,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m \n",
      "\n",
      "     part_number                     description  quantity   price  \\\n",
      "0      0312-0235  90/90-21 54r desert race front         0  352.99   \n",
      "1      0313-0873  140/80-18 70r desert race baja         0  520.99   \n",
      "2       10-05722                 commuter screen         0  295.99   \n",
      "3       11-08094      hat logo patch - dark grey         0   52.99   \n",
      "4    11117715453    seal kit, output shaft/swing         0   47.99   \n",
      "..           ...                             ...       ...     ...   \n",
      "128         p603             wheel rim lock 2.50         0   19.99   \n",
      "129    sm-15500g   s100 wheel cleaner gel- 500ml         0   21.99   \n",
      "130    sm-18400a    s100 detail & wax- 10oz/283g         0   21.99   \n",
      "131     t2051750                     chain guard         0   87.99   \n",
      "132     t3601276           o ring, id 23.7 x 2.9         0    3.99   \n",
      "\n",
      "     negative_on_hand  \n",
      "0                  -1  \n",
      "1                  -1  \n",
      "2                  -1  \n",
      "3                  -1  \n",
      "4                  -1  \n",
      "..                ...  \n",
      "128                -1  \n",
      "129                -1  \n",
      "130                -2  \n",
      "131                -1  \n",
      "132                -1  \n",
      "\n",
      "[133 rows x 5 columns]\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 17:51:35,258 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m \n",
      "\n",
      "    part_number           description  quantity  price previous_month  \\\n",
      "0   11127674654           rubber bush        28   6.99         august   \n",
      "1   11127674654           rubber bush        28   6.99       november   \n",
      "2   11137676132             isa screw         5   2.99       february   \n",
      "3   11137676132             isa screw         5   2.99           july   \n",
      "4   11137676132             isa screw         5   2.99            may   \n",
      "..          ...                   ...       ...    ...            ...   \n",
      "93     t3350301           nut, m8x1.2        24   1.99           july   \n",
      "94     t3558989       washer, sealing       108   1.99       november   \n",
      "95     t3558989       washer, sealing       108   1.99      september   \n",
      "96     t3600109        o-ring 5.6x2.2        10   3.99        january   \n",
      "97     t3600124  o-ring id 21.5 x 3.0        11   3.99        january   \n",
      "\n",
      "    previous_year  previous_month_sales next_month  next_year  \\\n",
      "0            2023                    56   december       2023   \n",
      "1            2023                    12    october       2023   \n",
      "2            2023                    13    january       2023   \n",
      "3            2023                    17       june       2023   \n",
      "4            2023                    17   november       2023   \n",
      "..            ...                   ...        ...        ...   \n",
      "93           2023                    12       june       2023   \n",
      "94           2023                    12    october       2023   \n",
      "95           2023                    59      april       2024   \n",
      "96           2023                    20       july       2023   \n",
      "97           2023                    17       july       2023   \n",
      "\n",
      "    current_month_sales  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "..                  ...  \n",
      "93                    0  \n",
      "94                    0  \n",
      "95                    0  \n",
      "96                    0  \n",
      "97                    0  \n",
      "\n",
      "[98 rows x 10 columns]\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 17:51:38,122 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 17:51:48,711 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-24 17:52:10,825 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively manage the inventory of high-demand parts, it is crucial to implement a proactive and data-driven approach. Given the current context, we have several parts that are either out of stock or in negative inventory, indicating an urgent need for restocking. Here is a detailed strategy for managing these high-demand parts:\n",
      "\n",
      "1. **Immediate Reordering**: For parts that are currently out of stock and in negative inventory, such as part numbers 0312-0235, 0313-0873, 10-05722, 11-08094, 11117715453, and sm-18400a, it is imperative to place immediate orders to replenish stock. These parts are in negative inventory, indicating they have been sold beyond the available stock, which directly translates to lost sales opportunities and potential customer dissatisfaction. Given their high price points, such as the 140/80-18 70r desert race baja at $520.99, the potential revenue loss is significant.\n",
      "\n",
      "2. **Safety Stock Levels**: Establish safety stock levels for each part based on their sales velocity. For instance, part numbers 11137676132, t3600109, and t3600124 have shown consistent monthly sales of 13-20 units. It would be prudent to maintain a safety stock that covers at least one and a half times the average monthly sales to buffer against unexpected spikes in demand. For these parts, maintaining a minimum safety stock of 30 units would be advisable.\n",
      "\n",
      "3. **Regular Inventory Audits**: Conduct regular inventory audits to ensure that stock levels are monitored and discrepancies are identified promptly. This will help in maintaining accurate stock records and avoiding situations where parts go into negative inventory.\n",
      "\n",
      "4. **Demand Forecasting**: Utilize historical sales data to forecast future demand accurately. For example, the washer, sealing (part number t3558989), which has sold 59 units in the previous month, suggests a high turnover rate. Forecasting tools can help predict demand trends and adjust ordering cycles accordingly to ensure that stock levels are optimized.\n",
      "\n",
      "5. **Supplier Relationships**: Strengthen relationships with suppliers to negotiate better lead times and terms. This can be particularly beneficial for high-demand parts to ensure quick replenishment and avoid stockouts. Prioritize establishing agreements with suppliers for parts that have shown consistent high sales, such as the o-rings and washers.\n",
      "\n",
      "6. **Automated Reordering Systems**: Implement automated reordering systems that trigger purchase orders when stock levels fall below predefined thresholds. This will ensure that high-demand parts are reordered in a timely manner without manual intervention, reducing the risk of human error.\n",
      "\n",
      "By adopting these strategies, the parts manager can effectively manage high-demand inventory, minimize stockouts, and maximize potential profits. Ensuring that high-demand items are always in stock will not only meet customer expectations but also drive sales and revenue growth.\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE CREW WITH AGENTS NEEDED FOR THE TASKS\n",
    "crew1 = Crew(\n",
    "    agents=[problem_parts_agent],\n",
    "    tasks=[identify_problems_task],\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "crew2 = Crew(\n",
    "    agents=[reorder_parts_agent, knowledge_agent],\n",
    "    tasks=[identify_reorders_task, fix_reorders_task],\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# RUN AGENTS TO SOLVE TASKS\n",
    "result = crew2.kickoff()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from the agents trying to solve example tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for the hybrid query engine ###\n",
    "(this wasn't working but idk if we'll use it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:47:59,415 - WARNING - Ignoring wrong pointing object 22 0 (offset 0)\n",
      "2024-06-19 09:47:59,519 - WARNING - Ignoring wrong pointing object 20 0 (offset 0)\n",
      "2024-06-19 09:47:59,595 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:47:59,596 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:47:59,598 - WARNING - Ignoring wrong pointing object 13 0 (offset 0)\n",
      "2024-06-19 09:47:59,599 - WARNING - Ignoring wrong pointing object 16 0 (offset 0)\n",
      "2024-06-19 09:47:59,600 - WARNING - Ignoring wrong pointing object 18 0 (offset 0)\n",
      "2024-06-19 09:47:59,601 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:47:59,602 - WARNING - Ignoring wrong pointing object 29 0 (offset 0)\n",
      "2024-06-19 09:47:59,862 - WARNING - Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2024-06-19 09:47:59,863 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:47:59,864 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:47:59,864 - WARNING - Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2024-06-19 09:48:00,033 - WARNING - Ignoring wrong pointing object 9 0 (offset 0)\n",
      "2024-06-19 09:48:00,034 - WARNING - Ignoring wrong pointing object 11 0 (offset 0)\n",
      "2024-06-19 09:48:00,036 - WARNING - Ignoring wrong pointing object 17 0 (offset 0)\n",
      "2024-06-19 09:48:00,037 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:48:00,158 - WARNING - Ignoring wrong pointing object 17 0 (offset 0)\n",
      "2024-06-19 09:48:00,260 - WARNING - Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2024-06-19 09:48:00,261 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:48:00,262 - WARNING - Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2024-06-19 09:48:00,263 - WARNING - Ignoring wrong pointing object 12 0 (offset 0)\n",
      "2024-06-19 09:48:00,263 - WARNING - Ignoring wrong pointing object 15 0 (offset 0)\n",
      "2024-06-19 09:48:00,264 - WARNING - Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2024-06-19 09:48:00,690 - WARNING - Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2024-06-19 09:48:00,692 - WARNING - Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2024-06-19 09:48:03,913 - WARNING - Ignoring wrong pointing object 19 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 7 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 14 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 16 0 (offset 0)\n",
      "2024-06-19 09:48:03,967 - WARNING - Ignoring wrong pointing object 30 0 (offset 0)\n",
      "2024-06-19 09:48:03,977 - WARNING - Ignoring wrong pointing object 32 0 (offset 0)\n",
      "2024-06-19 09:48:03,978 - WARNING - Ignoring wrong pointing object 34 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\\~$le_inventory_trend.docx with error: File is not a zip file. Skipping...\n",
      "Failed to load file C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\\~$le_stock.docx with error: File is not a zip file. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR HYBRID QUERY ENGINE THAT WASN'T WORKING\n",
    "# file reader for knowledge database\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\data\\knowledge_database\"\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir)\n",
    "knowledge_documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data from function tools\n",
    "tools_analysis_results = compile_analysis_results()\n",
    "\n",
    "# Converting dataframes into csvs\n",
    "for key in tools_analysis_results.keys():\n",
    "    base_path = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\\\\\"\n",
    "    file_name = key + \".csv\"\n",
    "    tools_analysis_results[key].to_csv(base_path + file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in csvs into documents\n",
    "tools_documents_dir = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\tools_data\"\n",
    "reader = SimpleDirectoryReader(input_dir=tools_documents_dir)\n",
    "tools_documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data into json document\n",
    "# json.dump(tools_analysis_results, out_file, indent=6)\n",
    "\n",
    "# out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json reader for tools data\n",
    "# from llama_index.readers.json import JSONReader\n",
    "# json_file = r\"C:\\Users\\vivia\\co-pilot-v1\\Notebooks\\index\\tools_data.json\"\n",
    "# reader = JSONReader()\n",
    "# keyword_documents = reader.load_data(input_file=json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "# from llama_index.core.node_parser import JSONNodeParser\n",
    "\n",
    "# parser = JSONNodeParser()\n",
    "knowledge_nodes = Settings.node_parser.get_nodes_from_documents(knowledge_documents)\n",
    "tools_nodes = Settings.node_parser.get_nodes_from_documents(tools_documents)\n",
    "# json_nodes = parser.get_nodes_from_documents(json_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_storage_context = StorageContext.from_defaults()\n",
    "vector_storage_context.docstore.add_documents(knowledge_nodes)\n",
    "\n",
    "keyword_storage_context = StorageContext.from_defaults()\n",
    "keyword_storage_context.docstore.add_documents(tools_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:56:28,715 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:30,032 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:32,444 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:33,751 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:35,667 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:36,865 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:38,465 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:40,552 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:56:40,967 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_CBEventType.EMBEDDING ->  1.383237 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.35824 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.356682 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.1506 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.095168 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.173531 seconds\n",
      "    |_CBEventType.EMBEDDING ->  2.530428 seconds\n",
      "    |_CBEventType.EMBEDDING ->  1.184701 seconds\n",
      "    |_CBEventType.EMBEDDING ->  0.181473 seconds\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleKeywordTableIndex, VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(tools_nodes, storage_context=keyword_storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(tools_nodes, storage_context=keyword_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import QueryBundle\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "# import NodeWithScore\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "# Retrievers\n",
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    "    KeywordTableSimpleRetriever,\n",
    ")\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both semantic search and hybrid search.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        keyword_retriever: KeywordTableSimpleRetriever,\n",
    "        mode: str = \"AND\",\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._keyword_retriever = keyword_retriever\n",
    "        if mode not in (\"AND\", \"OR\"):\n",
    "            raise ValueError(\"Invalid mode.\")\n",
    "        self._mode = mode\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        keyword_nodes = self._keyword_retriever.retrieve(query_bundle)\n",
    "\n",
    "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "        keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
    "\n",
    "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "        combined_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
    "\n",
    "        if self._mode == \"AND\":\n",
    "            retrieve_ids = vector_ids.intersection(keyword_ids)\n",
    "        else:\n",
    "            retrieve_ids = vector_ids.union(keyword_ids)\n",
    "\n",
    "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
    "        return retrieve_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# define custom retriever\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=2)\n",
    "keyword_retriever = KeywordTableSimpleRetriever(index=keyword_index)\n",
    "custom_retriever = CustomRetriever(vector_retriever, keyword_retriever)\n",
    "\n",
    "# define response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "custom_query_engine = RetrieverQueryEngine(\n",
    "    retriever=custom_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# vector query engine\n",
    "vector_query_engine = RetrieverQueryEngine(\n",
    "    retriever=vector_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "# keyword query engine\n",
    "keyword_query_engine = RetrieverQueryEngine(\n",
    "    retriever=keyword_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 09:57:01,516 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-19 09:57:01,602 - INFO - > Starting query: What are some parts from the roi csv\n",
      "2024-06-19 09:57:01,602 - INFO - query keywords: ['roi', 'parts', 'csv']\n",
      "2024-06-19 09:57:01,602 - INFO - > Extracted keywords: ['parts']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_CBEventType.QUERY ->  0.284426 seconds\n",
      "**********\n",
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "response = custom_query_engine.query(\"What are some parts from the roi csv\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PartsWise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
